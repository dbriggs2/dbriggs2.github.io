{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://o.aolcdn.com/images/dims?quality=85&image_uri=http%3A%2F%2Fo.aolcdn.com%2Fhss%2Fstorage%2Fmidas%2F670a1a33be1fcabdebe882b04d133666%2F203147314%2Flol-tencent-2015-12-17-01.jpg&client=amp-blogside-v2&signature=1d8f1a25702ca2f4924b74add55925a6b29ac80c\" />\n",
    "<h1 style=\"text-align:center\"> Analyzing League of Legends Champions and Match Statistics   </h1>\n",
    "<h6 style=\"text-align:center\"> Calvin Holman | Daniel Briggs | Christina Tobin </h6>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Introduction</center></h1>\n",
    "\n",
    "League of Legends (LoL) is a multi-player, fast-paced, and competitive online game that blends the speed and intensity of an RTS (Real-Time Strategy) with RPG (Role Playing Game) elements. Two teams of powerful champions, each with a unique design and playstyle, battle head-to-head across multiple battlefields and game modes. League was developed and published by Riot Games for Microsoft Windows and macOS in 2009. The last player statistics released by the company in 2016 showed League has 100 million active players each month. Outside companies estimate this number has continued to rise over the last 2 years. In League of Legends, players assume the role of a \"summoner\" who controls a \"champion\" with unique abilities. They battle against a team of other players or computer-controlled champions. The goal is usually to destroy the opposing team's \"nexus\", a structure that lies at the heart of a base protected by defensive structures, although other distinct game modes exist as well. Each League of Legends match has all champions starting off fairly weak but increasing in strength by accumulating items and experience.\n",
    "\n",
    "Besides serving as an online game for hobbyists, League of Legends has a developed competitive scene. In North America and Europe, Riot Games organizes the League Championship Series (LCS), located in Los Angeles and Berlin respectively, which consists of 10 professional teams from each continent. Similar regional competitions exist in China (LPL), South Korea (LCK), Taiwan/Hong Kong/Macau (LMS), and various other regions. These regional competitions culminate with the annual World Championship. The 2018 Mid-Season Invitational had an overall peak concurrent viewership of 19.8 million, while the finals had an average concurrent viewership of 11 million along with a multi-million dollar prize pool. \n",
    "\n",
    "Given the widespread interest in League and its professional tournament, our tutorial objective is to use player statistics from the 6 regions that made it to worlds, to predict the world championship team. This data from [Gamepedia ](https://lol.gamepedia.com/League_of_Legends_Esports_Wiki), is from the most recent season, 2018 summer season. In order to accurately predict the winning team, we will look at the players by position to decide if a single role has more influence over a team's win. This can be broken down into what variables, such a Kills, Deaths, and Assists (KDA) or GoldShare (how much of your team's gold you have), have helped teams wins in the regular season. We will apply that to a heuristic that assigns coefficents, or weighs reflecting importance, to those variables. Using machine learning, our heuristic will be able to predict the winner of the league chanpionship. \n",
    "\n",
    "In doing this analysis, we hope to spark interest in new players and provide exciting new information for existing ones. For both types of players, the tutorial should offer insight into the important factors of games and how to win. For more information on the game, see [here.](https://na.leagueoflegends.com/en/game-info/get-started/) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Getting Started</center></h1>\n",
    "\n",
    "The code for this will be in Python 3, making use of the available libraries such as [numPY](http://www.numpy.org/), [Pandas](https://pandas.pydata.org/), [bs4](https://www.crummy.com/software/BeautifulSoup/bs4/doc/), [sklearn](https://scikit-learn.org/stable/), and [statsmodel](https://www.statsmodels.org/stable/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lxml\n",
      "  Downloading https://files.pythonhosted.org/packages/03/a4/9eea8035fc7c7670e5eab97f34ff2ef0ddd78a491bf96df5accedb0e63f5/lxml-4.2.5-cp36-cp36m-manylinux1_x86_64.whl (5.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 5.8MB 62kB/s eta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: lxml\n",
      "Successfully installed lxml-4.2.5\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Libraries needed for the following tutorial\n",
    "!pip install lxml\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from itertools import chain\n",
    "from itertools import combinations\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Obtaining the Data</center></h1>\n",
    "\n",
    "The data, pulled from [Gamepedia](https://lol.gamepedia.com/League_of_Legends_Esports_Wiki), is obtained through GET requests and stored in variables r1 through r14. Most of the requests are for the regular season data for each region. When the data was originally read in, the information was saved into csv files. Since the start of our work, the website changed their data encoding so we will use the csv files to access the information. However, we have kept in the steps used to procure the data originally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET requests for all of the different datasets we will need. These are broken into 2 brackets as the large number of requests \n",
    "#will seem like an attack if they all go through at once. \n",
    "\n",
    "# Gather tournament data on all 90 players\n",
    "r = requests.get(\"https://lol.gamepedia.com/2018_Season_World_Championship/Main_Event/Player_Statistics\")\n",
    "\n",
    "# Regular season data from North America\n",
    "r2 = requests.get(\"https://lol.gamepedia.com/NA_LCS/2018_Season/Summer_Season/Player_Statistics\")\n",
    "\n",
    "# Regular Season data from EU\n",
    "r3 = requests.get(\"https://lol.gamepedia.com/EU_LCS/2018_Season/Summer_Season/Player_Statistics\")\n",
    "\n",
    "# Regular Season data from the LPL\n",
    "r4 = requests.get(\"https://lol.gamepedia.com/LPL/2018_Season/Summer_Season/Player_Statistics\")\n",
    "\n",
    "# Regular Season data from the LCK\n",
    "r5 = requests.get(\"https://lol.gamepedia.com/LCK/2018_Season/Summer_Season/Player_Statistics\")\n",
    "\n",
    "# Regular Season data from the LMS\n",
    "r6 = requests.get(\"https://lol.gamepedia.com/LMS/2018_Season/Summer_Season/Player_Statistics\")\n",
    "\n",
    "# Regular Season data from the VCS\n",
    "r7 = requests.get(\"https://lol.gamepedia.com/VCS/2018_Season/Summer_Season/Player_Statistics\")\n",
    "\n",
    "# Champion data from play-ins\n",
    "r8 = requests.get(\"https://lol.gamepedia.com/2018_Season_World_Championship/Main_Event/Champion_Statistics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match data from North America\n",
    "r9 = requests.get(\"https://lol.gamepedia.com/NA_LCS/2018_Season/Summer_Season\")\n",
    "\n",
    "# Match data from Europe\n",
    "r10 = requests.get(\"https://lol.gamepedia.com/EU_LCS/2018_Season/Summer_Season\")\n",
    "\n",
    "# Regular Season data from the LPL\n",
    "r11 = requests.get(\"https://lol.gamepedia.com/LPL/2018_Season/Summer_Season\")\n",
    "\n",
    "# Regular Season data from the LCK\n",
    "r12 = requests.get(\"https://lol.gamepedia.com/LCK/2018_Season/Summer_Season\")\n",
    "\n",
    "# Regular Season data from the LMS\n",
    "r13 = requests.get(\"https://lol.gamepedia.com/LMS/2018_Season/Summer_Season\")\n",
    "\n",
    "# Regular Season data from the VCS\n",
    "r14 = requests.get(\"https://lol.gamepedia.com/VCS/2018_Season/Summer_Season\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Data Tidying and Modification</center></h1>\n",
    "\n",
    "Now that all our data is read in and stored, we want to parse through it to get each team's data. Due to the way the website provides the information, several parsers are needed depending on the page. Data parsing and tidying, given the large amount of data needed and the numerous steps to modify and tidy it in the dataframes, is a significant part of our project. Tidied data will make the machine learning portion of our project much easier, so we spent a lot of time prepping the data. \n",
    "\n",
    "\n",
    "The first thing we looked at was the match data. We went through, getting the team's data, inserting NaN, a variable for non existant values, in place of empty or missing data slots, and disgarding unnecessary rows before we stored the information in a final dataframe called 'matchReg.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ee053f295fd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Overall\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"</tbody>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"</th></tr>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "ls = []\n",
    "matchReg = []\n",
    "j = 0\n",
    "\n",
    "# Parse with lxml\n",
    "ls.append(BeautifulSoup(r9.text, \"lxml\"))\n",
    "ls.append(BeautifulSoup(r10.text, \"lxml\"))\n",
    "ls.append(BeautifulSoup(r11.text, \"lxml\"))\n",
    "ls.append(BeautifulSoup(r12.text, \"lxml\"))\n",
    "ls.append(BeautifulSoup(r13.text, \"lxml\"))\n",
    "ls.append(BeautifulSoup(r14.text, \"lxml\"))\n",
    "\n",
    "# Number of teams for each region\n",
    "numTeams = [10,10,7,10,8,8]\n",
    "\n",
    "for bs in ls:\n",
    "    \n",
    "    # Different parsing rules for the LPL\n",
    "    if j==2:\n",
    "        bs = BeautifulSoup(r11.text, \"lxml\")\n",
    "\n",
    "        l = str(bs).split(\"title=\\\"Points\\\"\")[1:]\n",
    "\n",
    "        arr = []  # final array for the dataframe\n",
    "\n",
    "        # Loop for east and west region\n",
    "        for t in range(0,2):\n",
    "            l[t] = l[t].split(\"title=\\\"\")[1:]\n",
    "\n",
    "            l2 = []     # Remove unnecessary rows\n",
    "            l2 = [s for s in l[t] if \"std.png\" not in s]\n",
    "            l[t] = l2\n",
    "\n",
    "            l[t][numTeams[2]-1] = l[t][numTeams[2]-1].split(\"</div>\")[0]\n",
    "\n",
    "            # Get each team's data\n",
    "            for x in range(0,numTeams[2]):\n",
    "                l[t][x] = l[t][x].split(\"align=\\\"center\")\n",
    "                l2 = []\n",
    "                l2.append(l[t][x][0].split(\"\\\">\")[0])\n",
    "\n",
    "                # Different parsing rules for each region\n",
    "                if (t==2):\n",
    "                    l2.append(l[t][x][5][2:9])\n",
    "                else:\n",
    "                    l2.append(l[t][x][3][2:9])\n",
    "\n",
    "                # add to our final array\n",
    "                arr.append(l2)\n",
    "\n",
    "        # Create the dataframe\n",
    "        matchReg.append(pd.DataFrame(np.array(arr).reshape(len(arr),2), columns = ['Team', 'Record']))\n",
    "    \n",
    "    # Need to parse differently for the EU_LCS page\n",
    "    elif j==1:\n",
    "        \n",
    "        l = str(bs).split(\"Overall\")[1].split(\"</tbody>\")[0].split(\"</th></tr>\")[1:-1]\n",
    "        \n",
    "        for h in range(0,len(l)):\n",
    "            l[h] = l[h].split(\"style=\\\"background-color:\")\n",
    "            \n",
    "            # Team name  \n",
    "            l[h][0] = l[h][0].split(\"title=\")[1].split(\"\\\"><img alt\")[0][1:]\n",
    "            \n",
    "            # Get match data\n",
    "            for g in range(1,numTeams[j]+1):\n",
    "                tmpStr = l[h][g][6:]\n",
    "                tmpStr = 'blank' if tmpStr[0] == 'A' else tmpStr[0:5]\n",
    "                \n",
    "                l[h][g] = tmpStr\n",
    "            \n",
    "            l[h] = l[h][0:-1]\n",
    "            \n",
    "        teams = [\"Teams\"]\n",
    "        for t in l:\n",
    "            teams.append(t[0])\n",
    "            \n",
    "        # Create the dataframe\n",
    "        matchReg.append(pd.DataFrame(np.array(l).reshape(len(l),len(l[0])), columns = teams))\n",
    "\n",
    "        # Replace our spacer values with NaN to standardize it\n",
    "        matchReg[j] = matchReg[j].replace(\"blank\",np.nan)\n",
    "        \n",
    "    #lms and vcs \n",
    "    elif j==4 or j==5:\n",
    "        l = str(bs).split(\"Overall\")[1].split(\"</tbody>\")[0].split(\"</th></tr>\")[1:-1]\n",
    "        \n",
    "        for h in range(0,len(l)):\n",
    "            l[h] = l[h].split(\"style=\\\"background-color:\")\n",
    "            \n",
    "            # Team name  \n",
    "            l[h][0] = l[h][0].split(\"title=\")[1].split(\"\\\"><img alt\")[0][1:]\n",
    "            \n",
    "            l2 = []\n",
    "            l2 = [s for s in l[h] if \"display\" not in s]\n",
    "            l[h] = l2\n",
    "            \n",
    "            # Get match data\n",
    "            for g in range(1,numTeams[j]+1):\n",
    "                tmpStr = l[h][g][6:]\n",
    "                tmpStr = 'blank' if tmpStr[0] == 'A' else tmpStr[1:6]\n",
    "                \n",
    "                l[h][g] = tmpStr\n",
    "            \n",
    "            l[h] = l[h][0:-1]\n",
    "        \n",
    "            teams = [\"Teams\"]\n",
    "        for t in l:\n",
    "            teams.append(t[0])\n",
    "            \n",
    "        # Create the dataframe\n",
    "        matchReg.append(pd.DataFrame(np.array(l).reshape(len(l),len(l[0])), columns = teams))\n",
    "\n",
    "        # Replace our spacer values with NaN to standardize it\n",
    "        matchReg[j] = matchReg[j].replace(\"blank\",np.nan)\n",
    "      \n",
    "    # Default parser -> Works for NA_LCS and LCK\n",
    "    else:\n",
    "        l = str(bs).split(\"plainlinks crossbox\")[1].split(\"title=\")[1:]\n",
    "\n",
    "        # Get all of the teams\n",
    "        for x in range(0,numTeams[j]):\n",
    "            l[x] = l[x][1:]\n",
    "            l[x] = l[x].split(\"\\\"><img alt\")[0]\n",
    "\n",
    "        # Get all team names as the first element\n",
    "        l[0:numTeams[j]] = [','.join(l[0:numTeams[j]])]\n",
    "        l[0] = l[0].split(\",\")\n",
    "\n",
    "        # Get match data for each team\n",
    "        for t in range(1,numTeams[0]+1):\n",
    "            l[t] = l[t].split(\"<span class=\\\"crossbox-match-link\")[:-1]\n",
    "\n",
    "            # Get the score for how well each team did\n",
    "            for x in range(0,len(l[t])):\n",
    "                l[t][x] = l[t][x][-5:]\n",
    "\n",
    "            # Insert the team name at the beginning of the row\n",
    "            l[t].insert(0,l[0][t-1])\n",
    "\n",
    "        # Cut off unnecessary rows in the array\n",
    "        l = l[:numTeams[j]+1]\n",
    "\n",
    "        # Insert spacing because you can't play yourself\n",
    "        for t in range(1,numTeams[j]+1):\n",
    "            l[t].insert(t,'blank')\n",
    "            l[t] = l[t][:numTeams[j]+1]\n",
    "\n",
    "        # Insert new column\n",
    "        l[0].insert(0,'Teams')\n",
    "\n",
    "        # Create the dataframe\n",
    "        matchReg.append(pd.DataFrame(np.array(l[1:]).reshape(len(l)-1,len(l[0])), columns = l[0]))\n",
    "\n",
    "        # Replace our spacer values with NaN to standardize it\n",
    "        matchReg[j] = matchReg[j].replace(\"blank\",np.nan)\n",
    "    \n",
    "    j = j+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated above, since the website encodings changed, from here we used the csv's we originally stored the data we got with the above steps. The data read in from the CSVs were stored in our 'matchReg' dataframe. To make the information easier to use later in the tutorial by assigning some weight, we set the winner to be either 0 or 100 for each match. We then combined all the regional data in 'matchReg' into a master dataframed called 'masterMatch.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Since we stored the data into csv files, we can just read them in with pandas.\n",
    "matchReg = []\n",
    "matchReg.append(pd.read_csv(\"naMatchdat.csv\").drop('Unnamed: 0',axis=1))\n",
    "matchReg.append(pd.read_csv(\"EUMatchdat.csv\").drop('Unnamed: 0',axis=1))\n",
    "matchReg.append(pd.read_csv(\"LPLMatchdat.csv\").drop('Unnamed: 0',axis=1))\n",
    "matchReg.append(pd.read_csv(\"LCKMatchdat.csv\").drop('Unnamed: 0',axis=1))\n",
    "matchReg.append(pd.read_csv(\"LMSMatchdat.csv\").drop('Unnamed: 0',axis=1))\n",
    "matchReg.append(pd.read_csv(\"VCSMatchdat.csv\").drop('Unnamed: 0',axis=1))\n",
    "\n",
    "matchReg[0]['Region'] = 2\n",
    "matchReg[1]['Region'] = 4\n",
    "matchReg[2]['Region'] = 6\n",
    "matchReg[3]['Region'] = 5\n",
    "matchReg[4]['Region'] = 3\n",
    "matchReg[5]['Region'] = 1\n",
    "\n",
    "# We will set the winner to be either 0 or 100 to increase our weights.\n",
    "for x in range(0,len(matchReg)):\n",
    "    matchReg[x]['Winner'] = matchReg[x]['Winner']*100\n",
    "    t = matchReg[x].replace(0,5)\n",
    "    t = t.replace(100,0)\n",
    "    matchReg[x] = t.replace(5,100)\n",
    "    \n",
    "# Combine each region's data into one master dataframe\n",
    "masterMatch = pd.concat(matchReg).reset_index().drop('index',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have to parse the the regular season data for each region, also dropping unnecessary data, and adding it to a dataframe called 'reg'. Then, we tidy the data more by sorting the data in the dataframe by 'Games' and 'Player.' Lastly, because we plan to investigate how a player's position affects the winning heuristic, we needed to assign the data of position to each player. Unfortunately, the data read in didn;t track positions, and no single table available had this data, so instead of downloading and pasing 30 separate tables for a single column, we hardcoded in the player's position. There are five possible positions: Top, JG (jungler), Mid (Mid-Lane), ADC (Marksman/AD Carry), or Supp (Support). You can learn about the role of each position [here.](https://www.lol-smurfs.com/blog/lol-roles-explained/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Regular season data for each region\n",
    "# We also took precautions and decided to save this to a csv file once we combined all of the data together from each region.\n",
    "\n",
    "ls = []\n",
    "reg = []\n",
    "\n",
    "# Parse with lxml\n",
    "ls.append(BeautifulSoup(r2.text, \"lxml\"))\n",
    "ls.append(BeautifulSoup(r3.text, \"lxml\"))\n",
    "ls.append(BeautifulSoup(r4.text, \"lxml\"))\n",
    "ls.append(BeautifulSoup(r5.text, \"lxml\"))\n",
    "ls.append(BeautifulSoup(r6.text, \"lxml\"))\n",
    "ls.append(BeautifulSoup(r7.text, \"lxml\"))\n",
    "\n",
    "j = 0\n",
    "for bs in ls:\n",
    "    \n",
    "    # split to get all the players individually\n",
    "    players = str(bs).split(\"std.png/45px\")[1:]\n",
    "\n",
    "    # split to get each column\n",
    "    for x in range (0,len(players)):\n",
    "        players[x] = players[x].split(\"</td>\")\n",
    "\n",
    "        # Get the player's name\n",
    "        players[x][1] = players[x][1].split(\"title=\\\"\")[1].split(\"\\\"\")[0]\n",
    "\n",
    "        # Get the team name\n",
    "        players[x][0] = players[x][0][1:].split(\"_std.png\")[0][:-4]\n",
    "\n",
    "        for y in range (2,17):\n",
    "            players[x][y] = players[x][y].split(\"center\\\">\")[1].split('\\n')[0]\n",
    "            \n",
    "        players[x][17] = players[x][17][-18:-16]\n",
    "\n",
    "    # Convert into data frame\n",
    "    reg.append(pd.DataFrame(np.array(players).reshape(len(players),len(players[0])), columns = ['Team','Player','Games','Wins','Losses','Winrate','Kills','Deaths','Assists','KDA','CS','CSPM','Gold','GPM','Kill Participation','Kill Share','Gold Share','Champions Played','19','20']))\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    reg[j] = reg[j].drop(['19','20'],axis=1)\n",
    "    \n",
    "    # Get just numeric data\n",
    "    reg[j]['Games'] = reg[j]['Games'].str.extract('(\\d+)', expand=False)\n",
    "    reg[j]['Champions Played'] = reg[j]['Champions Played'].str.extract('(\\d+)', expand=False)\n",
    "    reg[j]['Gold'] = reg[j]['Gold'].str[:-1]\n",
    "    reg[j]['Gold Share'] = reg[j]['Gold Share'].str[:-1]\n",
    "    reg[j]['Kill Participation'] = reg[j]['Kill Participation'].str[:-1]\n",
    "    reg[j]['Kill Share'] = reg[j]['Kill Share'].str[:-1]\n",
    "        \n",
    "    j = j+1\n",
    "\n",
    "# reg contains regular season data by region\n",
    "# reg[0] --> North America (NA)\n",
    "# reg[1] --> Europe (EU)\n",
    "# reg[2] --> China (LPL)\n",
    "# reg[3] --> Korea (LCK)\n",
    "# reg[4] --> Taiwan (LMS)\n",
    "# reg[5] --> Vietnam (VCS)\n",
    "\n",
    "# Convert data into numeric form\n",
    "for t in reg:\n",
    "    k=0\n",
    "    for col in t.columns:\n",
    "        if k>1 and k<18:\n",
    "            t[col] = pd.to_numeric(t[col])\n",
    "        k=k+1\n",
    "        \n",
    "# Sort the tables based on 'Games' and 'Player' to standardize the view\n",
    "reg[0] = reg[0].sort_values(['Games','Player'],ascending=[False,True])\n",
    "reg[1] = reg[1].sort_values(['Games','Player'],ascending=[False,True])\n",
    "reg[2] = reg[2].sort_values(['Games','Player'],ascending=[False,True])\n",
    "reg[3] = reg[3].sort_values(['Games','Player'],ascending=[False,True])\n",
    "reg[4] = reg[4].sort_values(['Games','Player'],ascending=[False,True])\n",
    "reg[5] = reg[5].sort_values(['Games','Player'],ascending=[False,True])\n",
    "\n",
    "#pos = ['Top','ADC','Mid','JG','Top','Supp','Mid','Supp','ADC','Top','ADC','JG','JG','Mid','Top','Supp','Mid','Top','JG','JG','Mid','Mid','Supp','ADC','ADC','Top','Supp','ADC','Top','Top','Supp','ADC','Mid','Top','Supp','ADC','JG','Supp','Supp','JG','Mid','JG','Mid','JG','Top','Mid','ADC','Supp','ADC','ADC','JG','JG','Supp','Mid','JG','Mid','ADC','Top','Supp','JG','Supp','JG','ADC','Supp','Mid','JG','Top']\n",
    "pos = ['Supp', 'Mid', 'ADC', 'JG', 'Top', 'JG', 'Top', 'Top', 'Mid',\n",
    "       'Supp', 'Mid', 'JG', 'Top', 'ADC', 'ADC', 'ADC', 'Supp', 'Supp',\n",
    "       'JG', 'ADC', 'ADC', 'Mid', 'Mid', 'Top', 'Top', 'Top', 'Supp',\n",
    "       'Supp', 'Mid', 'Mid', 'Top', 'ADC', 'JG', 'Top', 'JG', 'ADC',\n",
    "       'Supp', 'Supp', 'JG', 'Mid', 'JG', 'Supp', 'JG', 'Mid', 'Top',\n",
    "       'Mid', 'Supp', 'ADC', 'ADC', 'ADC', 'JG', 'JG', 'Supp', 'Mid',\n",
    "       'Mid', 'JG', 'Top', 'ADC', 'Supp', 'Supp', 'Mid', 'JG', 'JG', 'ADC',\n",
    "       'Supp', 'JG', 'Top']\n",
    "reg[0]['Position'] = pos\n",
    "\n",
    "#pos1 = ['Mid','Mid','Supp','Supp','Top','Supp','JG','ADC','Top','Top','JG','ADC','Mid','ADC','Mid','JG','Supp','ADC','JG','Mid','Mid','Mid','ADC','Mid','ADC','JG','Mid','Top','Supp','Supp','Top','Supp','Supp','Top','Supp','Top','ADC','Top','JG','JG','Top','JG','ADC','Supp','ADC','Top','Mid','JG','JG','ADC','JG','JG','ADC','ADC','Mid','Supp']\n",
    "#pos1 = ['JG','ADC','Supp','Mid','Supp','Top','Supp','JG','ADC','Top','Top','Mid','Mid','ADC','JG','Mid','Mid','Mid','ADC','JG','Mid','Mid','ADC','Mid','ADC','JG','Top','Supp','Top','JG','Supp','JG','Top','JG','Top','Top','Supp','Supp','Supp','ADC','Top','Supp','ADC','ADC','Supp','Top','Mid','JG','ADC','JG','JG','ADC','JG','ADC','Mid','Supp']\n",
    "pos1 = ['JG', 'ADC', 'Top', 'ADC', 'Supp', 'JG', 'Mid', 'Mid', 'Mid', 'ADC',\n",
    "       'Supp', 'Top', 'Supp', 'Top', 'Top', 'Mid', 'Mid', 'JG', 'Mid',\n",
    "       'JG', 'Mid', 'ADC', 'ADC', 'Supp', 'Supp', 'ADC', 'JG', 'JG', 'JG',\n",
    "       'Mid', 'Supp', 'Top', 'Top', 'Supp', 'Top', 'Mid', 'Supp', 'Top',\n",
    "       'ADC', 'Supp', 'Top', 'JG', 'ADC', 'ADC', 'Supp', 'Top', 'Mid',\n",
    "       'JG', 'JG', 'JG', 'ADC', 'JG', 'ADC', 'ADC', 'Supp', 'Mid']\n",
    "reg[1]['Position'] = pos1\n",
    "\n",
    "#pos2 = ['Supp','ADC','JG','Supp','Top','Mid','Top','Mid','Supp','JG','JG','ADC','Mid','Top','Top','Mid','Mid','JG','ADC','Supp','Supp','ADC','ADC','Top','Supp','ADC','Supp','Supp','Top','Top','ADC','Mid','Mid','Mid','Top','Supp','ADC','Mid','JG','JG','Top','Top','JG','Mid','Supp','Supp','Supp','Top','ADC','Supp','JG','Mid','Top','JG','ADC','Mid','ADC','Mid','ADC','Supp','Mid','JG','JG','ADC','ADC','JG','Top','JG','ADC','JG','Mid','Top','JG','JG','Top','ADC','Mid','JG','JG','Supp','JG','Top','JG','ADC','ADC','Top','Mid','JG','JG','Mid','ADC','ADC','Top','Mid','Top','ADC','Supp','Supp','ADC','JG','Supp','Mid']\n",
    "pos2 = ['JG','ADC','Supp','Mid','Top','JG','Mid','Top','Top','Supp','ADC','Supp','Mid','Supp','Top','ADC','JG','JG','Mid','Supp','Mid','Supp','Top','Mid','ADC','Supp','ADC','Supp','Top','Mid','ADC','Top','ADC','JG','Supp','Top','Supp','Mid','ADC','Supp','Top','Mid','Top','JG','Supp','ADC','JG','Mid','Top','JG','ADC','JG','JG','Supp','Top','ADC','Mid','JG','Top','Mid','JG','ADC','ADC','Mid','ADC','Mid','JG','Supp','Top','JG','Top','Mid','JG','Top','Mid','JG','Top','ADC','ADC','JG','ADC','JG','Mid','JG','Supp','JG','ADC','Mid','Supp','ADC','Top','JG','JG','Top','ADC','Mid','ADC','ADC','JG','Supp','Mid','Supp']\n",
    "reg[2]['Position'] = pos2\n",
    "\n",
    "#pos3 = ['Supp','Mid','Top','ADC','Supp','Top','Supp','Mid','Supp','Top','ADC','Top','ADC','Mid','Supp','Supp','Top','Mid','JG','Mid','ADC','Supp','Top','JG','Supp','Mid','JG','Mid','Top','Top','Top','Mid','ADC','Top','ADC','Supp','ADC','JG','ADC','ADC','JG','ADC','JG','Mid','Supp','JG','JG','Mid','JG','JG','JG','JG','ADC','JG','JG','Mid','Supp','JG','ADC','JG','Supp','ADC','JG','Mid','ADC','Mid','Top','Top','ADC','Supp','Top']\n",
    "pos3 = ['Top', 'Mid', 'Supp', 'Supp', 'Mid', 'Top', 'Supp', 'ADC', 'JG',\n",
    "       'Top', 'ADC', 'Supp', 'Mid', 'ADC', 'Top', 'Mid', 'Top', 'Top',\n",
    "       'ADC', 'Supp', 'Supp', 'Supp', 'ADC', 'Mid', 'Top', 'Mid', 'ADC',\n",
    "       'Mid', 'Mid', 'Supp', 'Top', 'JG', 'JG', 'ADC', 'JG', 'Top', 'JG',\n",
    "       'ADC', 'Supp', 'ADC', 'Top', 'Supp', 'JG', 'JG', 'JG', 'ADC', 'Mid',\n",
    "       'JG', 'JG', 'Mid', 'Mid', 'JG', 'JG', 'ADC', 'JG', 'Supp', 'Mid',\n",
    "       'JG', 'JG', 'Supp', 'JG', 'ADC', 'ADC', 'JG', 'Mid', 'ADC', 'Supp',\n",
    "       'Top', 'ADC', 'Top', 'Top']\n",
    "reg[3]['Position'] = pos3\n",
    "\n",
    "#pos4 = ['Supp','Top','Mid','JG','Supp','Top','Top','JG','Supp','Supp','ADC','Supp','Mid','ADC','ADC','Mid','JG','Mid','Top','Supp','ADC','ADC','Mid','ADC','JG','Mid','ADC','Top','Supp','Supp','ADC','Top','JG','Mid','Top','JG','Mid','JG','ADC','Top','JG','Top','JG','ADC','JG','Mid','Top','JG','JG','Top','JG','Top','Supp','ADC','JG','Supp','Supp','Supp','JG','JG']\n",
    "pos4 = ['Supp', 'Top', 'JG', 'Mid', 'Top', 'Supp', 'ADC', 'Mid', 'ADC',\n",
    "       'Top', 'JG', 'Supp', 'Supp', 'JG', 'Mid', 'ADC', 'Supp', 'ADC',\n",
    "       'Supp', 'ADC', 'Mid', 'Top', 'ADC', 'Mid', 'JG', 'Mid', 'Top',\n",
    "       'ADC', 'Supp', 'Supp', 'Top', 'ADC', 'Top', 'JG', 'Mid', 'Mid',\n",
    "       'JG', 'JG', 'ADC', 'Top', 'JG', 'Top', 'ADC', 'JG', 'JG', 'Mid',\n",
    "       'Top', 'JG', 'JG', 'JG', 'Top', 'ADC', 'Top', 'Supp', 'JG', 'Supp',\n",
    "       'Supp', 'Supp', 'JG', 'JG']\n",
    "reg[4]['Position'] = pos4\n",
    "\n",
    "#pos5 = ['Top','ADC','Supp','Mid','ADC','Mid','Top','Top','Mid','Supp','Mid','JG','JG','JG','ADC','Mid','ADC','Top','Mid','Top','Supp','JG','ADC','Top','ADC','Supp','JG','ADC','Supp','JG','JG','Supp','Supp','Mid','Top','ADC','ADC','JG','Supp','Mid','Top','JG','Supp','Mid','Top','Top','Supp','Mid','JG','ADC','Supp','Supp','Supp','JG','Mid','Supp','JG','Top','JG','Mid']\n",
    "pos5 = ['ADC', 'Mid', 'Supp', 'Top', 'ADC', 'Top', 'JG', 'Mid', 'Supp',\n",
    "       'ADC', 'JG', 'Top', 'Mid', 'Mid', 'JG', 'Mid', 'ADC', 'Top', 'Supp',\n",
    "       'Mid', 'Top', 'JG', 'Top', 'ADC', 'Supp', 'ADC', 'JG', 'ADC',\n",
    "       'Supp', 'JG', 'Supp', 'JG', 'Supp', 'Top', 'Mid', 'ADC', 'ADC',\n",
    "       'JG', 'Supp', 'Mid', 'Top', 'JG', 'Supp', 'Mid', 'Top', 'Top',\n",
    "       'Supp', 'Mid', 'JG', 'ADC', 'Supp', 'Supp', 'Supp', 'Mid', 'JG',\n",
    "       'Supp', 'JG', 'Top', 'JG', 'Mid']\n",
    "reg[5]['Position'] = pos5\n",
    "\n",
    "# Combine regular season player data from each region into a master table\n",
    "masterReg = pd.concat(reg).sort_values(['Games','Player'],ascending=[False,True]).reset_index().drop('index',axis=1)\n",
    "#masterReg.to_csv('masterReg.csv')  # Save the data for use later on so we don't have to parse every time.\n",
    "\n",
    "# Read in the table since we saved it already.\n",
    "masterReg = pd.read_csv(\"masterReg.csv\").drop(\"Unnamed: 0\",axis=1)\n",
    "\n",
    "# List of all column vars\n",
    "vars = ['KDA', 'GPM', 'Kill Share', 'Kill Participation', 'Kills', 'Deaths', 'Assists','Gold', 'Gold Share', 'CS', 'CSPM', 'Champions Played']\n",
    "\n",
    "# Create tables based on player position for our machine learning model.\n",
    "top = masterReg[masterReg['Position']=='Top']\n",
    "jg = masterReg[masterReg['Position']=='JG']\n",
    "mid = masterReg[masterReg['Position']=='Mid']\n",
    "adc = masterReg[masterReg['Position']=='ADC']\n",
    "supp = masterReg[masterReg['Position']=='Supp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we get the champion data from Worlds. Like the previous dataframes, the parsed data is being put into a dataframe called 'champs', using only the columns needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Champion data from worlds\n",
    "\n",
    "# Parse with lxml\n",
    "bs = BeautifulSoup(r8.text, \"lxml\")\n",
    "\n",
    "# split to get all champions individually\n",
    "tmp = str(bs).split(\"Square.png/40px\")[1:]\n",
    "\n",
    "# split to get each column\n",
    "for x in range (0,len(tmp)):\n",
    "    \n",
    "    tmp[x] = tmp[x].split(\"</td>\")\n",
    "    \n",
    "    # Get the Champion's name\n",
    "    tmp[x][0] = tmp[x][0].split(\"title=\\\"\")[1].split(\"\\\"\")[0]\n",
    "    \n",
    "    # Get other column data\n",
    "    for y in range (1,19):\n",
    "        if y==5 or y==6:\n",
    "            tmp[x][y] = tmp[x][y].split(\"</b>\")[0]\n",
    "        if y != 7:\n",
    "            tmp[x][y] = tmp[x][y].split(\"center\\\">\")[1].split(\"\\n\")[0]\n",
    "    \n",
    "    t = tmp[x][7].split(\"_blank\\\">\") \n",
    "    tmp[x][7] = 0 if len(t)==1 else t[1][:2]\n",
    "\n",
    "# Convert into data frame with appropriate columns\n",
    "champs = pd.DataFrame(np.array(tmp).reshape(len(tmp),len(tmp[0])), columns = ['Champion','Bans','Games','Wins','Losses','Winrate','PB','By','Kills','Deaths','Assists','KDA','CS','CSPM','Gold','GPM','Kill Participation','Kill Share','Gold Share', '20'])\n",
    "\n",
    "# Drop unnecessary columns\n",
    "champs = champs.drop('20',axis=1)\n",
    "\n",
    "# Get just numeric data\n",
    "champs['By'] = champs['By'].str.extract('(\\d+)', expand=False)\n",
    "champs['Gold'] = champs['Gold'].str[:-1]\n",
    "champs['Kill Participation'] = champs['Kill Participation'].str[:-1]\n",
    "champs['Kill Share'] = champs['Kill Share'].str[:-1]\n",
    "champs['Gold Share'] = champs['Gold Share'].str[:-1]\n",
    "champs['Winrate'] = champs['Winrate'].str[3:]\n",
    "champs['PB'] = champs['PB'].str[3:]\n",
    "\n",
    "# Making data NaN for champs banned, but not played.\n",
    "pat = re.compile('-1')\n",
    "for col in champs.columns:\n",
    "    champs[col] = champs[col].replace(pat, np.nan)\n",
    "\n",
    "# Save the data as a csv so we don't have to parse it every time.\n",
    "champs.to_csv(\"champs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Deciding Makes A Player 'Good' Using Machine Learning</center></h1>\n",
    "\n",
    "Now that the data is in dataframes, we are ready to start out machine learning to develop our heuristic to predict the winner of Worlds. The first bit of machine learning we want to do is determine what makes a player good.To do this, we will be using winrate as our y value, and all of the different player statistics as our x variables. The results will tell us which of the different variables are important and how important each one is individually. \n",
    "\n",
    "First, we separated all of the data into their own positions, because what makes a mid laner good is probably different from\n",
    "what makes a support good.\n",
    "\n",
    "Next, we have to determine which variables we should be using to figure out their weights, or coefficients. To do this, we\n",
    "created a powerset function that returns every possible combination of the variables we can have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code for this function was taken from:\n",
    "#     https://codereview.stackexchange.com/questions/178225/computing-the-powerset-of-a-list\n",
    "\n",
    "# Powerset function of a given list\n",
    "def gen_powerset(l):\n",
    "    if not l:  # List is empty\n",
    "        yield []\n",
    "        return\n",
    "    for sub_powerset in gen_powerset(l[1:]): # Generate next list\n",
    "        yield sub_powerset\n",
    "        yield [l[0]] + sub_powerset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we removed outliers from the data that would significantly impact the results. This is due to us using winrate as our\n",
    "measure of how good a player is. For example, if we have a substitute player that only played one game, and won, our algorithm\n",
    "thinks that he is the best player in the world. To remove outliers, we tested each dataset with at least 'x' games played\n",
    "by players to see what the cutoff should be. We don't want to remove more than 10 games, because that would encrouch on the\n",
    "regular season starters for some regions, so we looked at 0-10 for each region.\n",
    "\n",
    "The code below is linear regression in machine learning for predicitive analysis. Here we provide some links to extra reading material to familarize yourself with linear regression and how it is used, to understand the next part of our tutorial. \n",
    "\n",
    "A [Source](https://towardsdatascience.com/linear-regression-using-python-ce21aa90ade6) on what linear regression is and why we use it. \n",
    "  \n",
    "An [Example](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html) of basic linear regression\n",
    "\n",
    "A [Source](https://datatofish.com/multiple-linear-regression-python/) on linear regression of multi-variables, which is the type we did\n",
    "\n",
    "A [Source](https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) to understand the purpose and basic use of test and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an example of how we determined the cutoffs for each position. This was done on the adc table.\n",
    "\n",
    "# Must have played at least 0-10 games.\n",
    "for u in range(0,10):\n",
    "    \n",
    "    # All of the variables we want to look at\n",
    "    vars = ['KDA', 'GPM', 'Kill Share', 'Kill Participation', 'Kills', 'Deaths', 'Assists','Gold', 'Gold Share', 'CS', 'CSPM']\n",
    "\n",
    "    # Must have played at least 'u' games\n",
    "    tmp = adc[adc['Games'] >= u]\n",
    "\n",
    "    best = -1    # Keeps track of the best variance\n",
    "    bestLs = []  # Holds the list of variables for the best variance\n",
    "    coef = []    # Contains the coefficients for the variables\n",
    "    \n",
    "    # Set winrate to be our ranking for the players\n",
    "    y = tmp['Winrate']\n",
    "\n",
    "    # Look at every possible combination of variables for the players\n",
    "    for ps in gen_powerset(vars):\n",
    "        \n",
    "        if ps: # Dont include empty list\n",
    "            \n",
    "            X = tmp[ps]\n",
    "            \n",
    "            # Split data into test and training sets with an 80/20 split, which is standard to minimize overfitting.\n",
    "            # 80% of the data is used for training and the remaining 20% is used for testing.\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "            \n",
    "            # Fit the model to the training data\n",
    "            regr = linear_model.LinearRegression()\n",
    "            regr.fit(X_train, y_train)\n",
    "\n",
    "            #numpy array that contains all the predicted values for the input values in the X series.\n",
    "            y_pred = regr.predict(X_test)\n",
    "\n",
    "            # Get the variance score between the test data and our prediction. 1 would be a perfect score.\n",
    "            residuals = r2_score(y_test, y_pred)\n",
    "\n",
    "            # Keep track of the best score and which variables we used.\n",
    "            if residuals > best:\n",
    "                best = residuals\n",
    "                bestLs = ps\n",
    "                coef = regr.coef_\n",
    "                \n",
    "    print(str(u) + \": \" + str(best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this output, we see that if we look at just players that have played at least 6 games our variance goes all the way\n",
    "up to a 93% accuracy. If we used every player, so at least 0 games played, we would have an 89% accuracy. In the end, this\n",
    "should help our model be more consistent by removing outliers in the data. We're allowed to do this because it makes sense \n",
    "heuristically, and we still have a sizeable portion of the regular data. This removes the problem of having a person that\n",
    "went 1/1 in their games and our algorithm tries to use them as the best player.\n",
    "\n",
    "By having 10 be our max we want to cut out, it ensures that we keep starters for each region, as well as players that split\n",
    "time like the junglers for Cloud9, Svenskeren and Blaber. The only players we remove are substitutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This shows us that we are still using 86% of the main data, so we aren't cutting out a significant portion.\n",
    "len(adc[adc['Games']>=6])/len(adc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeated this process for each position and came up with the following numbers for minimum games played:\n",
    "\n",
    "top - 7<br>\n",
    "jg - 2<br>\n",
    "mid - 4<br>\n",
    "adc - 6<br>\n",
    "supp - 7<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We adjust the position tables accordingly.\n",
    "top = top[top['Games']>=7]\n",
    "jg = jg[jg['Games']>=2]\n",
    "mid = mid[mid['Games']>=4]\n",
    "adc = adc[adc['Games']>=6]\n",
    "supp = supp[supp['Games']>=7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to look at each position and figure out which variables we want to use now that we removed our outliers. using linear regression, we utilize the powerset created above to run through every combination of variables and see which generates the closet fit for our model and therefore the best prediction. The next few blaocks run through the code to predict what makes a player in a certain position do well. We show the code for the position 'top' but by changing th position passed in, we generated results for all positions (not shown). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOP MODEL\n",
    "# Look at the top 20 results\n",
    "numResults = 20\n",
    "\n",
    "# Must have played at least 7 games\n",
    "tmp = top[top['Games'] >= 7]\n",
    "\n",
    "#These are the possible column variables to be tested in combinations\n",
    "vars = ['KDA', 'GPM', 'Kill Share', 'Kill Participation', 'Kills', 'Deaths', 'Assists','Gold', 'Gold Share', 'CS', 'CSPM']\n",
    "\n",
    "best = [-1]*numResults   # Array of top 20 variance scores\n",
    "bestLs = [-1]*numResults # Array of corresponding variables to each of the variance scores\n",
    "coef = [[-1]]*numResults # Array of weights associated with each of the variables producing the variance scores\n",
    "\n",
    "y = tmp['Winrate']\n",
    "\n",
    "for ps in gen_powerset(vars):\n",
    "    if ps:\n",
    "        X = tmp[ps]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "        regr = linear_model.LinearRegression()\n",
    "        regr.fit(X_train, y_train)\n",
    "        y_pred = regr.predict(X_test)\n",
    "        residuals = r2_score(y_test, y_pred)\n",
    "\n",
    "        # Compares and tracks the best variances\n",
    "        for x in range(0,len(best)):\n",
    "\n",
    "            if residuals > best[x]:\n",
    "                best[x] = residuals\n",
    "                bestLs[x] = ps\n",
    "                coef[x] = regr.coef_\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear regression gives us the top 20 variance scores. 1 would be a perfect prediction, so having a value in the 80th or 90th percentile is a good prediction. For top, the variance is between 90 and 94 percent. Since the difference in the variances of the top 20 are so small, we decided to go through and pick the heuristic that makes the most sense. This uses basic league knowledge, but for those unfamilar with league, we have listed the main thing we looked for that helped us pick the heuristic below. Doing this saves us from picking just the top heuristic that may have been the best on our particular data set because of skewed input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This will show us the variance score, what variables it included and what the weights are for them.\n",
    "for x in range(0,len(coef)):\n",
    "    print(\"Var: \" + str(best[x]))\n",
    "    for y in range(0,len(coef[x])):\n",
    "        print(bestLs[x][y] + \": \" + str(coef[x][y]))\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST MODEL\n",
    "# Look at the top 20 results\n",
    "numResults = 20\n",
    "\n",
    "#These are the possible column variables to be tested in combinations\n",
    "vars = ['KDA', 'GPM', 'Kill Share', 'Kill Participation', 'Kills', 'Deaths', 'Assists','Gold', 'CS', 'CSPM']\n",
    "\n",
    "best = [-1]*numResults   # Array of top 20 variance scores\n",
    "bestLs = [-1]*numResults # Array of corresponding variables to each of the variance scores\n",
    "coef = [[-1]]*numResults # Array of weights associated with each of the variables producing the variance scores\n",
    "\n",
    "y = mid['Winrate']\n",
    "\n",
    "for ps in gen_powerset(vars):\n",
    "    if ps:\n",
    "        X = mid[ps]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "        regr = linear_model.LinearRegression()\n",
    "        regr.fit(X_train, y_train)\n",
    "        y_pred = regr.predict(X_test)\n",
    "        residuals = r2_score(y_test, y_pred)\n",
    "\n",
    "        # Compares and tracks the best variances\n",
    "        for x in range(0,len(best)):\n",
    "\n",
    "            if residuals > best[x]:\n",
    "                best[x] = residuals\n",
    "                bestLs[x] = ps\n",
    "                coef[x] = regr.coef_\n",
    "                break\n",
    "                \n",
    "for x in range(0,len(coef)):\n",
    "    print(\"Var: \" + str(best[x]))\n",
    "    for y in range(0,len(coef[x])):\n",
    "        print(bestLs[x][y] + \": \" + str(coef[x][y]))\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#These are the results we came up with for each position.\n",
    "\n",
    "Top<br>\n",
    "Var: 0.931949972536<br>\n",
    "KDA: 2.09811734882<br>\n",
    "GPM: 0.593191309816<br>\n",
    "Kill Participation: 0.386431392477<br>\n",
    "Kills: -5.46362811076<br>\n",
    "Gold: 12.5323771206<br>\n",
    "Gold Share: -14.2182616141<br>\n",
    "CS: -0.449448292041<br>\n",
    "CSPM: 8.51130983888<br>\n",
    "\n",
    "For a top laner, it looks like you shouldn't be focusing on kills to let your team get them instead, but KDA is also positive\n",
    "so that encourages you to have more assists. Gold is important, which makes sense because gold is used to buy items, which \n",
    "makes you stronger. However, we see that Gold Share is fairly negative, meaning you should be getting gold, but not at the \n",
    "expense of your team's gold.\n",
    "\n",
    "Jungle<br>\n",
    "Var: 0.934277194926<br>\n",
    "KDA: 0.181164206403<br>\n",
    "GPM: 0.735342254784<br>\n",
    "Kills: -2.68009575084<br>\n",
    "Deaths: -7.25541495648<br>\n",
    "Assists: 1.85733953438<br>\n",
    "Gold: 7.16660335062<br>\n",
    "Gold Share: -14.1978168455<br>\n",
    "CS: -0.385377553174<br>\n",
    "CSPM: 10.493478078<br>\n",
    "\n",
    "Jungle follows roughly the same logic as top: you want assists, not kills, and you don't want to take a large portion of the\n",
    "team's gold.\n",
    "\n",
    "Mid<br>\n",
    "Var: 0.901898303047<br>\n",
    "GPM: 0.0713156133641<br>\n",
    "Deaths: -13.0255264467<br>\n",
    "Assists: 3.69342852617<br>\n",
    "Gold: 19.8616597461<br>\n",
    "CS: -0.845745453945<br>\n",
    "CSPM: 12.7679155894<br>\n",
    "\n",
    "For some reason the algorithm wanted to have use Gold Share and have it be negative, which doesn't really make sense for a mid\n",
    "laner, because you normally want them to have a high percentage of the team's gold. I think the reason this happened is because\n",
    "of the data itself. Gold Share, no matter of the position, is always going to be around 20% because it's split between 5 people.\n",
    "Because we didn't think this would be a good predictor, we excluded it from our results and looked for a different model. This\n",
    "is what we came up with, which still works pretty well. It has a focus on Gold, CSPM, and assists, while also punishing deaths.\n",
    "\n",
    "ADC<br>\n",
    "Var: 0.933270580443<br>\n",
    "KDA: 0.879083138604<br>\n",
    "GPM: 1.13044121708<br>\n",
    "Kill Share: 1.03542306739<br>\n",
    "Kill Participation: -0.335817323575<br>\n",
    "Kills: -12.9697993181<br>\n",
    "Assists: 4.65262777296<br>\n",
    "CS: 0.128173966315<br>\n",
    "CSPM: -11.2995505544<br>\n",
    "Gold Share: -12.5435852695<br>\n",
    "\n",
    "We ran into the same issue with Gold Share when doing the adc data, but without Gold Share included the variance scores dropped\n",
    "too low to be used. To rectify this, we just used the top result and decided not to influence the results in any way. The model\n",
    "seems to think that kills, gold share, kill participation, and cspm are all negative, which is counter-intuitive for any\n",
    "league of legends adc. Normally your job is to get kills, be involved, and get as much gold as you can so that you can carry\n",
    "your team by dealing the most damage. Since this doesn't line up with our intuition, we'll see how the results are at the end\n",
    "and talk more about this.\n",
    "\n",
    "Supp<br>\n",
    "Var: 0.915741666545<br>\n",
    "KDA: 0.0316139479741<br>\n",
    "GPM: 1.338934096<br>\n",
    "Kill Share: -0.145858503846<br>\n",
    "Kills: -3.99163808505<br>\n",
    "Deaths: -6.05433184202<br>\n",
    "Gold Share: -23.0728233467<br>\n",
    "\n",
    "For a support, kills should be negative because you don't want to be taking kills/gold away from your team. Again this follows\n",
    "roughly the same pattern as top and jungle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Predicting the Winner with Machine Learning</center></h1>\n",
    "\n",
    "Now that we have generated a heuristic for each position, we will use the weights we got from our machine learning and use them to calculate a player's winrate. We will do this by using the variables and associated weights profuced by our heuristic for each position to create the calculated winrate. We are then adding this as a new column to our dataframe. These calculated winrates will be used in linear regression again to predict future winners. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the calculated value to the the corresponding table position\n",
    "\n",
    "top['CalculatedWinrate'] = 2.09811734882*top['KDA'] + 0.593191309816*top['GPM'] + 0.386431392477*top['Kill Participation'] + -5.46362811076*top['Kills'] + 12.5323771206*top['Gold'] + -14.2182616141*top['Gold Share'] + -0.449448292041*top['CS'] + 8.51130983888*top['CSPM']\n",
    "jg['CalculatedWinrate'] = 0.181164206403*jg['KDA'] + 0.735342254784*jg['GPM'] + -2.68009575084*jg['Kills'] + -7.25541495648*jg['Deaths'] + 1.85733953438*jg['Assists'] + 7.16660335062*jg['Gold'] + -14.1978168455*jg['Gold Share'] + -0.385377553174*jg['CS'] + 10.493478078*jg['CSPM']\n",
    "mid['CalculatedWinrate'] = mid['GPM']*0.0713156133641 + mid['Deaths']*-13.0255264467 + mid['Gold']*19.8616597461 + mid['CS']*-0.845745453945 + mid['CSPM']*12.7679155894 + mid['Assists']*3.69342852617\n",
    "adc['CalculatedWinrate'] = 1.13044121708*adc['GPM'] + 1.03542306739*adc['Kill Share'] + -0.335817323575*adc['Kill Participation'] + -12.9697993181*adc['Kills'] + 4.65262777296*adc['Assists'] + 0.128173966315*adc['CS'] + -11.2995505544*adc['CSPM'] + -12.5435852695*adc['Gold Share']\n",
    "supp['CalculatedWinrate'] = 1.338934096*supp['GPM'] + -0.145858503846*supp['Kill Share'] + -3.99163808505*supp['Kills'] + -6.05433184202*supp['Deaths'] + -23.0728233467*supp['Gold Share']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use machine learning to predict games. First we need to calculate the difference in the calculated winrate\n",
    "for each position and save them as variables. We will do this for each game. These will be the independent variables for our ML and the dependent variable will be which team won, a value either 0 or 100. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "teams = {}                # Dictionary ('Team' -> [topDiff, jgDiff,...])\n",
    "nadd = [[],[],[],[],[]]   # Contains new columns to be added to masterMatch\n",
    "\n",
    "# Go through each game we have data saved for.\n",
    "for index,row in masterMatch.iterrows():\n",
    "    \n",
    "    x1 = [] # Team 0 data\n",
    "    x2 = [] # Team 1 data\n",
    "    \n",
    "    # If we haven't seen this team yet, add it to the dictionary\n",
    "    if not row['Team 0'] in teams:\n",
    "        tmp = []\n",
    "        tmp.append(top[top['Team']==row['Team 0']])\n",
    "        tmp.append(jg[jg['Team']==row['Team 0']])\n",
    "        tmp.append(mid[mid['Team']==row['Team 0']])\n",
    "        tmp.append(adc[adc['Team']==row['Team 0']])\n",
    "        tmp.append(supp[supp['Team']==row['Team 0']])\n",
    "        \n",
    "        for x in tmp:\n",
    "            if len(x) == 1: # If there's only 1 player at that position, add them in\n",
    "                x1.append(x['CalculatedWinrate'])\n",
    "            else:\n",
    "                x1.append(x['CalculatedWinrate'].mean())  # If there are multiple players, we take the average\n",
    "                \n",
    "        # Save the team data in the dictionary for use later on\n",
    "        teams[row['Team 0']] = x1\n",
    "        \n",
    "    else:\n",
    "        x1 = teams[row['Team 0']]\n",
    "    \n",
    "    # Repeat the process for the next team\n",
    "    if not row['Team 1'] in teams:\n",
    "        tmp = []\n",
    "        tmp.append(top[top['Team']==row['Team 1']])\n",
    "        tmp.append(jg[jg['Team']==row['Team 1']])\n",
    "        tmp.append(mid[mid['Team']==row['Team 1']])\n",
    "        tmp.append(adc[adc['Team']==row['Team 1']])\n",
    "        tmp.append(supp[supp['Team']==row['Team 1']])\n",
    "        \n",
    "        for x in tmp:\n",
    "            if len(x) == 1:\n",
    "                x2.append(x['CalculatedWinrate'])\n",
    "            else:\n",
    "                x2.append(x['CalculatedWinrate'].mean())\n",
    "                \n",
    "        teams[row['Team 1']] = x2\n",
    "    \n",
    "    else:\n",
    "        x2 = teams[row['Team 1']]\n",
    "       \n",
    "    # Calculate the difference for each lane\n",
    "    for x in range(0,5):\n",
    "        nadd[x].append(float(x1[x]) - float(x2[x]))\n",
    "    \n",
    "# Update masterMatch with the new data\n",
    "masterMatch['TopDiff'] = nadd[0]\n",
    "masterMatch['JGDiff'] = nadd[1]\n",
    "masterMatch['MidDiff'] = nadd[2]\n",
    "masterMatch['ADCDiff'] = nadd[3]\n",
    "masterMatch['SuppDiff'] = nadd[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run ML on the masterMatch table using our calculated differences as the X, and the winner result as the y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = masterMatch\n",
    "\n",
    "# Calculated Differences\n",
    "vars = ['TopDiff','JGDiff','MidDiff','ADCDiff','SuppDiff']\n",
    "\n",
    "y = tester['Winner']  # Winner data\n",
    "\n",
    "X = tester[vars]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred = regr.predict(X_test)\n",
    "residuals = r2_score(y_test, y_pred)\n",
    "                \n",
    "print(\"Var: \" + str(residuals))\n",
    "print(regr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our results, we can see that our variance score is 30%. This isn't ideal, especially considering we were expecting at\n",
    "least a value over 50%, which would be a blind guess. The model seems to think that top and jungle are negatively weighted,\n",
    "meaning that teams with a worse top and jungle will win a game. This is counter-intuitive to us because normally the team\n",
    "with better players wins more often. It is also worth noting that support is the largest value here by a decent margin,\n",
    "implying that teams with a better support win more often. Who knows? Maybe support is the most important position. The data\n",
    "seems to think so. Now we will simulate matches in Worlds to see how well the model does, despite it going against our \n",
    "intuition.\n",
    "\n",
    "Next we will Simulate matches! Just enter 2 teams and look at the result. Negative means the team on the right will win. Positive means the team on the left will win. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def matchup(team1,team2):\n",
    "    l = teams[team1]\n",
    "    l2 = teams[team2]\n",
    "\n",
    "    # Get the data to be the right type\n",
    "    for x in range(0,5):\n",
    "        if isinstance(l[x],pd.Series):\n",
    "            l[x] = l[x].values[0]\n",
    "    for x in range(0,5):\n",
    "        if isinstance(l2[x],pd.Series):\n",
    "            l2[x] = l2[x].values[0]\n",
    "\n",
    "    t = l[0] - l2[0]   # Calculate the differences\n",
    "    j = l[1] - l2[1]\n",
    "    m = l[2] - l2[2]\n",
    "    a = l[3] - l2[3]\n",
    "    s = l[4] - l2[4]\n",
    "\n",
    "    # Calculate the results\n",
    "    res = t*-0.12769662 + j*-0.09652615 + m*0.00205015 + a*0.28178966  + s*1.12903653\n",
    "\n",
    "    if res>0:\n",
    "        print(\"The winner is \" + team1 + \" by a differential of \" + str(res))\n",
    "        return team1\n",
    "    else:\n",
    "        print(\"The winner is \" + team2 + \" by a differential of \" + str(res))\n",
    "        return team2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regRank = {}\n",
    "regRank[0] = 2\n",
    "regRank[1] = 4\n",
    "regRank[2] = 6\n",
    "regRank[3] = 5\n",
    "regRank[4] = 3\n",
    "regRank[5] = 1\n",
    "\n",
    "# Simulate matches! Just enter 2 teams and look at the result! It's that easy!\n",
    "# Negative means the team on the right will win. Positive means the team on the left will win\n",
    "\n",
    "def matchup2(team1,team2):\n",
    "    l = teams[team1]\n",
    "    l2 = teams[team2]\n",
    "\n",
    "    # Get the data to be the right type\n",
    "    for x in range(0,5):\n",
    "        if isinstance(l[x],pd.Series):\n",
    "            l[x] = l[x].values[0]\n",
    "    for x in range(0,5):\n",
    "        if isinstance(l2[x],pd.Series):\n",
    "            l2[x] = l2[x].values[0]\n",
    "\n",
    "    t = l[0] - l2[0]   # Calculate the differences\n",
    "    j = l[1] - l2[1]\n",
    "    m = l[2] - l2[2]\n",
    "    a = l[3] - l2[3]\n",
    "    s = l[4] - l2[4]\n",
    "    r = regRank[region(team1)] - regRank[region(team2)]\n",
    "\n",
    "    # Calculate the results\n",
    "    res = t*-0.12769662 + j*-0.09652615 + m*0.00205015 + a*0.28178966  + s*1.12903653 + r\n",
    "\n",
    "    if res>0:\n",
    "        print(\"The winner is \" + team1 + \" by a differential of \" + str(res))\n",
    "        return team1\n",
    "    else:\n",
    "        print(\"The winner is \" + team2 + \" by a differential of \" + str(res))\n",
    "        return team2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will simulate the group stage, by doing a round-robin of the teams in each group and ranking them by wins.\n",
    "group = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will simulate the group stage, by doing a round-robin of the teams in each group and ranking them by wins.\n",
    "We input all of the teams in each group as a list and go through each group, storing the resulting dataframe in 'group'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = []\n",
    "rank = {}\n",
    "groupTeams = []\n",
    "groupTeams.append([\"Freecs\", \"G2_Esports\", \"Yoe_Flash_Wolves\", \"Phong_V%C5%A9_Buffalo\"])\n",
    "groupTeams.append([\"Team_Vitality\", \"Cloud9\", \"Royal_Never_Give_Up\", \"Gen.G\"])\n",
    "groupTeams.append([\"KTRolster\", \"EDward_Gaming\", \"MAD_Team\", \"Team_Liquid\"])\n",
    "groupTeams.append([\"Invictus_Gaming\", \"Fnatic\", \"100_Thieves\", \"G-Rex\"])\n",
    "\n",
    "for l in groupTeams:\n",
    "    for x in l:\n",
    "        rank[x] = 0\n",
    "\n",
    "    l2 = list(combinations(l,2))\n",
    "\n",
    "    for x in range(0,len(l2)):\n",
    "        winner = matchup(l2[x][0],l2[x][1])\n",
    "        rank[winner] = rank[winner]+1\n",
    "\n",
    "    final = []\n",
    "    for x in l:\n",
    "        final.append([x,rank[x]])\n",
    "\n",
    "    group.append(pd.DataFrame(final,columns=['Team','Wins']).sort_values('Wins',ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the results for the group stage with our model.<br>\n",
    "GROUP A: 4,3,2,1. It predicted the teams in reverse order, which isn't ideal. <br>\n",
    "GROUP B: 2,1,3,4. It got 2/4 correct, but just switched first and second place. That's really good though because the\n",
    "        top 2 teams from each group move on, so it predicted those teams correctly, it just messed up on the seeding.<br>\n",
    "GROUP C: 3,4,1,2. It was almost in reverse order, and didn't get any of the finalists correctly. <br>\n",
    "GROUP D: 2,1,3,4. It did the same as group B where it only switched the top 2 teams, which is pretty good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in group:\n",
    "    print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One reason the model might not be performing very well is that we aren't considering strength of schedule. For example, if one team does really well during the regular season because they play against bad teams, the model thinks they're better than a \n",
    "team that did decently well in a tough region. We can't add that in as a parameter because all of our data is teams playing\n",
    "against each other in the same region, which would cancel out and become zero. Since we don't have any international data,\n",
    "we can't do this with machine learning, so we will attempt to create our own model and incorporate it in. \n",
    "\n",
    "First, we need a way to tell what region a team is in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region(teamName):\n",
    "    for x in range(0,6):\n",
    "        if teamName in matchReg[x]['Team 0'].unique():\n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to actually rank the regions from best to worse. Region ranking has the highest being the best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regRank = {}\n",
    "regRank[0] = 2\n",
    "regRank[1] = 4\n",
    "regRank[2] = 6\n",
    "regRank[3] = 5\n",
    "regRank[4] = 3\n",
    "regRank[5] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model from best to worst region: LPL, LCK, EU, LMS, NA, VCS.<br>\n",
    "This ranking is purely heuristic, and will only impact the data by a small amount. At most, it will change a result by 5\n",
    "points. The results we've calculated range anywhere from 1 to 30, so it should have an impact, but not a large one. By doing\n",
    "this, it will only impact matches that are really close and hopefully push them over the edge in our favor.\n",
    "\n",
    "To incorporate this into the final ranking, the following line would be added to our group stage code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = regRank[region(team1)] - regRank[region(team2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we add in the regional difference, our results change for the group stage by a little.<br>\n",
    "In group A, it now ranks them 3,4,2,1 instead of 4,3,2,1. So it's a little better, but not by much.<br>\n",
    "In group C, it now ranks them 3,1,2,4 instead of 3,4,1,2. So again it's a little better.<br>\n",
    "\n",
    "If we had more time we would definitely look into grabbing some international data to train the model on regional difference\n",
    "and add that in as a factor, because it would make the model slightly better.\n",
    "\n",
    "Now that we finished the group stage, we will look at the elimination bracket given the starting teams in the bracket. The\n",
    "following results are without the strength of schedule variable added in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elimination Round Results:\n",
    "\n",
    "Africa Freecs --<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;16.9&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;>---Cloud9---<br>\n",
    "Cloud 9 --------             ><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;>----Cloud9---- <br>\n",
    "Fnatic ---------             >                     ><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5.5&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;>---Fnatic---                      ><br>\n",
    "EDG ------------                                   ><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;14&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;>---Invictus Gaming !!<br>\n",
    "KT Rolster -----                                   ><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;28.7&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;>---Inv. G---                      ><br>\n",
    "Invictus Gaming-             >                     ><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;19.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;>---Invictus Gaming---<br>\n",
    "Royal Never G.--             ><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;>----RNG-----<br>\n",
    "G2 Esports -----<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model predicts all of the first round winners correctly, except for RNG vs. G2. This match was an upset, with G2 coming\n",
    "out on top, and a lot of people had RNG winning the entire tournament. So it's reasonable that our code got it wrong, however,\n",
    "despite that it only had RNG winning by a margin of 4, which is pretty close considering some of the other margins we have\n",
    "between 10-30.\n",
    "\n",
    "In the semifinals, we predicted Cloud9 to beat Fnatic, which was incorrect, and we predicted Invictus to move on, which was\n",
    "correct.\n",
    "\n",
    "In the final match, we predicted Invictus Gaming to win, which was correct. Just for fun, we also ran the actual final matchup,\n",
    "which was Fnatic vs. Invictus Gaming, and the result was Invictus Gaming winning with a margin of 26. 26 is a pretty big\n",
    "margin compared to some of the numbers we've been getting, and that makes sense because they won 3-0 in a best of 5 series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matchup(\"Fnatic\", \"Invictus_Gaming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchReg[5]\n",
    "matchup(\"Team_Liquid\", \"Fnatic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is what our model thought would happen given the results of the group stage using the strength of schedule metric.\n",
    "\n",
    "Flash Wolves --<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;18.9&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;>---Flash Wolves---<br>\n",
    "Royal Never G. --------             ><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;>----Invictus Gaming---- <br>\n",
    "Invictus Gaming ---------             >                     ><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;29.7&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;>---Inv. G---                      ><br>\n",
    "KT Rolster ------------                                   ><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.8&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;>---Invictus Gaming !!<br>\n",
    "Team Liquid -----                                   ><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.16&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;>---Liquid---                      ><br>\n",
    "Fnatic-             >                     ><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;24.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;>---PV Buffalo---<br>\n",
    "Cloud 9.--             ><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;16.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;>----PV Buffalo-----<br>\n",
    "PV Buffalo -----<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we don't use the strength of schedule metric, then Flash Wolves would've won over Invictus Gaming, and \n",
    "Phong Vu Buffalo would've beaten Invictus Gaming in the final. It is also worth noting that with the strength of schedule\n",
    "metric, Fnatic almost beat Team Liquid; only losing by .16 instead of 2.16."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Conclusion and Followup</center></h1>\n",
    "\n",
    "Overall, our model did pretty well considering the small amount of data we added in. We could have expanded this and included\n",
    "data from every region, not just the ones that made it to worlds, and we could have added data from the spring split for\n",
    "those regions. We also saw the importance of a strength of schedule metric that ended up being the deciding factor for some\n",
    "close games. We did a very simple metric of just ranking regions 1-6 and taking the difference. This could've been done with\n",
    "machine learning to figure out the weights for the difference to see how important it is, and we could've done some ML to\n",
    "determine the rankings of each region, rather than doing it heuristically. With all of these factors in mind, it's pretty\n",
    "impressive that the model worked as well as it did. We only looked at player data, and for each player we only used a portion\n",
    "of their stats that the model told us to use. For some of the positions, ADC especially, these results were very counter\n",
    "intuitive, like having kills and gold share be negatively weighed. Despite this, we trusted the model and went ahead with the\n",
    "calculations and still predicted the winner of worlds correctly, even when we used our results from the group-stage that\n",
    "weren't very good. \n",
    "\n",
    "followip----\n",
    "\n",
    "This model could easily be updated with new data as the tournament progressed too, hopefully making it more accurate.\n",
    "For example, after the group stage you could add that player data to your existing data and be able to better predict the\n",
    "eliminiation round. \n",
    "\n",
    "Look up reference for this-> Another popular metric people use is having the data be weighed chronologically, where more recent\n",
    "data is more important than older data. This could be another addition to make the model even better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
