{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes and stuff:\n",
    "\n",
    "# Can we predict games?\n",
    "#  -Use regular season data. Maybe compare each laner individually when looking at players?\n",
    "\n",
    "# What makes a player good? -need to come up with a heuristic, -> Winrate.\n",
    "#  -What is/are the most important values in a player? Is it kda or something less known like cs/m\n",
    "#  -Look at similarities between people with a higher rating based on our heuristic\n",
    "\n",
    "# Role importance?\n",
    "#  -Does a single role have more influence over a team's win. For example do teams with a better mid laner win more often.\n",
    "#  -Need the rating system first\n",
    "\n",
    "# DATA:\n",
    "\n",
    "# Player data from Worlds -> playersWorlds\n",
    "\n",
    "# Champion data from Worlds play-ins -> champs\n",
    "\n",
    "# Player data from regular season by region -> reg\n",
    "#   reg[0] --> North America (NA)\n",
    "#   reg[1] --> Europe (EU)\n",
    "#   reg[2] --> China (LPL)\n",
    "#   reg[3] --> Korea (LCK)\n",
    "#   reg[4] --> Taiwan (LMS)\n",
    "#   reg[5] --> Vietnam (VCS)\n",
    "\n",
    "# Match data from regular season by region -> matchReg\n",
    "#   matchReg[0] --> North America (NA)\n",
    "#   matchReg[1] --> Europe (EU)\n",
    "#   matchReg[2] --> China (LPL)\n",
    "#   matchReg[3] --> Korea (LCK)\n",
    "#   matchReg[4] --> Taiwan (LMS)\n",
    "#   matchReg[5] --> Vietnam (VCS)\n",
    "\n",
    "# Link of what league is for noobs (christina)\n",
    "# https://na.leagueoflegends.com/en/game-info/get-started/\n",
    "\n",
    "# Picture of 2018 Worlds Icon\n",
    "# https://d1u5p3l4wpay3k.cloudfront.net/lolesports_gamepedia_en/thumb/5/5b/Worlds_2018.png/1200px-Worlds_2018.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.6/site-packages\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# GET requests for all of the different datasets we will need.\n",
    "\n",
    "# Gather tournament data on all 90 players\n",
    "r = requests.get(\"https://lol.gamepedia.com/2018_Season_World_Championship/Main_Event/Player_Statistics\")\n",
    "\n",
    "# Regular season data from North America\n",
    "r2 = requests.get(\"https://lol.gamepedia.com/NA_LCS/2018_Season/Summer_Season/Player_Statistics\")\n",
    "\n",
    "# Regular Season data from EU\n",
    "r3 = requests.get(\"https://lol.gamepedia.com/EU_LCS/2018_Season/Summer_Season/Player_Statistics\")\n",
    "\n",
    "# Regular Season data from the LPL\n",
    "r4 = requests.get(\"https://lol.gamepedia.com/LPL/2018_Season/Summer_Season/Player_Statistics\")\n",
    "\n",
    "# Regular Season data from the LCK\n",
    "r5 = requests.get(\"https://lol.gamepedia.com/LCK/2018_Season/Summer_Season/Player_Statistics\")\n",
    "\n",
    "# Regular Season data from the LMS\n",
    "r6 = requests.get(\"https://lol.gamepedia.com/LMS/2018_Season/Summer_Season/Player_Statistics\")\n",
    "\n",
    "# Regular Season data from the VCS\n",
    "r7 = requests.get(\"https://lol.gamepedia.com/VCS/2018_Season/Summer_Season/Player_Statistics\")\n",
    "\n",
    "# Champion data from play-ins\n",
    "r8 = requests.get(\"https://lol.gamepedia.com/2018_Season_World_Championship/Main_Event/Champion_Statistics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 20 into shape (10,11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-af88b72c29fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;31m# Create the dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mmatchReg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# Replace our spacer values with NaN to standardize it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 20 into shape (10,11)"
     ]
    }
   ],
   "source": [
    "# Match data from each region\n",
    "\n",
    "# The website changed the way they encoded their data, so the parser for the match data doesn't work anymore, but luckily we\n",
    "# saved all of the data to a csv file which we will be using instead. But this is how we got the data in the first place from\n",
    "# their website.\n",
    "\n",
    "# Match data from North America\n",
    "r9 = requests.get(\"https://lol.gamepedia.com/NA_LCS/2018_Season/Summer_Season\")\n",
    "\n",
    "# Match data from Europe\n",
    "r10 = requests.get(\"https://lol.gamepedia.com/EU_LCS/2018_Season/Summer_Season\")\n",
    "\n",
    "# Regular Season data from the LPL\n",
    "r11 = requests.get(\"https://lol.gamepedia.com/LPL/2018_Season/Summer_Season\")\n",
    "\n",
    "# Regular Season data from the LCK\n",
    "r12 = requests.get(\"https://lol.gamepedia.com/LCK/2018_Season/Summer_Season\")\n",
    "\n",
    "# Regular Season data from the LMS\n",
    "r13 = requests.get(\"https://lol.gamepedia.com/LMS/2018_Season/Summer_Season\")\n",
    "\n",
    "# Regular Season data from the VCS\n",
    "r14 = requests.get(\"https://lol.gamepedia.com/VCS/2018_Season/Summer_Season\")\n",
    "\n",
    "ls = []\n",
    "matchReg = []\n",
    "j = 0\n",
    "\n",
    "# Parse with lxml\n",
    "ls.append(BeautifulSoup(r9.text, \"lxml\"))\n",
    "ls.append(BeautifulSoup(r10.text, \"lxml\"))\n",
    "ls.append(BeautifulSoup(r11.text, \"lxml\"))\n",
    "ls.append(BeautifulSoup(r12.text, \"lxml\"))\n",
    "ls.append(BeautifulSoup(r13.text, \"lxml\"))\n",
    "ls.append(BeautifulSoup(r14.text, \"lxml\"))\n",
    "\n",
    "# Number of teams for each region\n",
    "numTeams = [10,10,7,10,8,8]\n",
    "\n",
    "for bs in ls:\n",
    "    \n",
    "    # Different parsing rules for the LPL\n",
    "    if j==2:\n",
    "        bs = BeautifulSoup(r11.text, \"lxml\")\n",
    "\n",
    "        l = str(bs).split(\"title=\\\"Points\\\"\")[1:]\n",
    "\n",
    "        arr = []  # final array for the dataframe\n",
    "\n",
    "        # Loop for east and west region\n",
    "        for t in range(0,2):\n",
    "            l[t] = l[t].split(\"title=\\\"\")[1:]\n",
    "\n",
    "            l2 = []     # Remove unnecessary rows\n",
    "            l2 = [s for s in l[t] if \"std.png\" not in s]\n",
    "            l[t] = l2\n",
    "\n",
    "            l[t][numTeams[2]-1] = l[t][numTeams[2]-1].split(\"</div>\")[0]\n",
    "\n",
    "            # Get each team's data\n",
    "            for x in range(0,numTeams[2]):\n",
    "                l[t][x] = l[t][x].split(\"align=\\\"center\")\n",
    "                l2 = []\n",
    "                l2.append(l[t][x][0].split(\"\\\">\")[0])\n",
    "\n",
    "                # Different parsing rules for each region\n",
    "                if (t==2):\n",
    "                    l2.append(l[t][x][5][2:9])\n",
    "                else:\n",
    "                    l2.append(l[t][x][3][2:9])\n",
    "\n",
    "                # add to our final array\n",
    "                arr.append(l2)\n",
    "\n",
    "        # Create the dataframe\n",
    "        matchReg.append(pd.DataFrame(np.array(arr).reshape(len(arr),2), columns = ['Team', 'Record']))\n",
    "    \n",
    "    # Need to parse differently for the EU_LCS page\n",
    "    elif j==1:\n",
    "        \n",
    "        l = str(bs).split(\"Overall\")[1].split(\"</tbody>\")[0].split(\"</th></tr>\")[1:-1]\n",
    "        \n",
    "        for h in range(0,len(l)):\n",
    "            l[h] = l[h].split(\"style=\\\"background-color:\")\n",
    "            \n",
    "            # Team name  \n",
    "            l[h][0] = l[h][0].split(\"title=\")[1].split(\"\\\"><img alt\")[0][1:]\n",
    "            \n",
    "            # Get match data\n",
    "            for g in range(1,numTeams[j]+1):\n",
    "                tmpStr = l[h][g][6:]\n",
    "                tmpStr = 'blank' if tmpStr[0] == 'A' else tmpStr[0:5]\n",
    "                \n",
    "                l[h][g] = tmpStr\n",
    "            \n",
    "            l[h] = l[h][0:-1]\n",
    "            \n",
    "        teams = [\"Teams\"]\n",
    "        for t in l:\n",
    "            teams.append(t[0])\n",
    "            \n",
    "        # Create the dataframe\n",
    "        matchReg.append(pd.DataFrame(np.array(l).reshape(len(l),len(l[0])), columns = teams))\n",
    "\n",
    "        # Replace our spacer values with NaN to standardize it\n",
    "        matchReg[j] = matchReg[j].replace(\"blank\",np.nan)\n",
    "        \n",
    "    #lms and vcs \n",
    "    elif j==4 or j==5:\n",
    "        l = str(bs).split(\"Overall\")[1].split(\"</tbody>\")[0].split(\"</th></tr>\")[1:-1]\n",
    "        \n",
    "        for h in range(0,len(l)):\n",
    "            l[h] = l[h].split(\"style=\\\"background-color:\")\n",
    "            \n",
    "            # Team name  \n",
    "            l[h][0] = l[h][0].split(\"title=\")[1].split(\"\\\"><img alt\")[0][1:]\n",
    "            \n",
    "            l2 = []\n",
    "            l2 = [s for s in l[h] if \"display\" not in s]\n",
    "            l[h] = l2\n",
    "            \n",
    "            # Get match data\n",
    "            for g in range(1,numTeams[j]+1):\n",
    "                tmpStr = l[h][g][6:]\n",
    "                tmpStr = 'blank' if tmpStr[0] == 'A' else tmpStr[1:6]\n",
    "                \n",
    "                l[h][g] = tmpStr\n",
    "            \n",
    "            l[h] = l[h][0:-1]\n",
    "        \n",
    "            teams = [\"Teams\"]\n",
    "        for t in l:\n",
    "            teams.append(t[0])\n",
    "            \n",
    "        # Create the dataframe\n",
    "        matchReg.append(pd.DataFrame(np.array(l).reshape(len(l),len(l[0])), columns = teams))\n",
    "\n",
    "        # Replace our spacer values with NaN to standardize it\n",
    "        matchReg[j] = matchReg[j].replace(\"blank\",np.nan)\n",
    "      \n",
    "    # Default parser -> Works for NA_LCS and LCK\n",
    "    else:\n",
    "        l = str(bs).split(\"plainlinks crossbox\")[1].split(\"title=\")[1:]\n",
    "\n",
    "        # Get all of the teams\n",
    "        for x in range(0,numTeams[j]):\n",
    "            l[x] = l[x][1:]\n",
    "            l[x] = l[x].split(\"\\\"><img alt\")[0]\n",
    "\n",
    "        # Get all team names as the first element\n",
    "        l[0:numTeams[j]] = [','.join(l[0:numTeams[j]])]\n",
    "        l[0] = l[0].split(\",\")\n",
    "\n",
    "        # Get match data for each team\n",
    "        for t in range(1,numTeams[0]+1):\n",
    "            l[t] = l[t].split(\"<span class=\\\"crossbox-match-link\")[:-1]\n",
    "\n",
    "            # Get the score for how well each team did\n",
    "            for x in range(0,len(l[t])):\n",
    "                l[t][x] = l[t][x][-5:]\n",
    "\n",
    "            # Insert the team name at the beginning of the row\n",
    "            l[t].insert(0,l[0][t-1])\n",
    "\n",
    "        # Cut off unnecessary rows in the array\n",
    "        l = l[:numTeams[j]+1]\n",
    "\n",
    "        # Insert spacing because you can't play yourself\n",
    "        for t in range(1,numTeams[j]+1):\n",
    "            l[t].insert(t,'blank')\n",
    "            l[t] = l[t][:numTeams[j]+1]\n",
    "\n",
    "        # Insert new column\n",
    "        l[0].insert(0,'Teams')\n",
    "\n",
    "        # Create the dataframe\n",
    "        matchReg.append(pd.DataFrame(np.array(l[1:]).reshape(len(l)-1,len(l[0])), columns = l[0]))\n",
    "\n",
    "        # Replace our spacer values with NaN to standardize it\n",
    "        matchReg[j] = matchReg[j].replace(\"blank\",np.nan)\n",
    "    \n",
    "    j = j+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Since we stored the data into csv files, we can just read them in with pandas.\n",
    "matchReg = []\n",
    "matchReg.append(pd.read_csv(\"naMatchdat.csv\").drop('Unnamed: 0',axis=1))\n",
    "matchReg.append(pd.read_csv(\"EUMatchdat.csv\").drop('Unnamed: 0',axis=1))\n",
    "matchReg.append(pd.read_csv(\"LPLMatchdat.csv\").drop('Unnamed: 0',axis=1))\n",
    "matchReg.append(pd.read_csv(\"LCKMatchdat.csv\").drop('Unnamed: 0',axis=1))\n",
    "matchReg.append(pd.read_csv(\"LMSMatchdat.csv\").drop('Unnamed: 0',axis=1))\n",
    "matchReg.append(pd.read_csv(\"VCSMatchdat.csv\").drop('Unnamed: 0',axis=1))\n",
    "\n",
    "matchReg[0]['Region'] = 2\n",
    "matchReg[1]['Region'] = 4\n",
    "matchReg[2]['Region'] = 6\n",
    "matchReg[3]['Region'] = 5\n",
    "matchReg[4]['Region'] = 3\n",
    "matchReg[5]['Region'] = 1\n",
    "\n",
    "# Some data manipulation to make our lives easier down the road.\n",
    "# We will set the winner to be either 0 or 100 to increase our weights.\n",
    "for x in range(0,len(matchReg)):\n",
    "    matchReg[x]['Winner'] = matchReg[x]['Winner']*100\n",
    "    t = matchReg[x].replace(0,5)\n",
    "    t = t.replace(100,0)\n",
    "    matchReg[x] = t.replace(5,100)\n",
    "    \n",
    "# Combine each region's data into one master dataframe\n",
    "masterMatch = pd.concat(matchReg).reset_index().drop('index',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Player data for the Worlds Tournament\n",
    "\n",
    "# Parse with lxml\n",
    "bs = BeautifulSoup(r.text, \"lxml\")\n",
    "\n",
    "# split to get all 90 players individually\n",
    "players = str(bs).split(\"std.png/45px\")[1:]\n",
    "\n",
    "# split to get each column\n",
    "for x in range (0,len(players)):\n",
    "    players[x] = players[x].split(\"</td>\")\n",
    "    \n",
    "    # Get the team name\n",
    "    players[x][0] = players[x][0][1:].split(\"_std.png\")[0][:-4]\n",
    "    \n",
    "    # Get the player's name\n",
    "    players[x][1] = players[x][1].split(\"title=\\\"\")[1].split(\"\\\">\")[0]\n",
    "    \n",
    "    for y in range (2,19):\n",
    "        if y!=17:\n",
    "            players[x][y] = players[x][y].split(\"center\\\">\")[1].split(\"\\n\")[0]\n",
    "    \n",
    "    players[x][17] = players[x][17][-17]\n",
    "\n",
    "# Convert into data frame with appropriate columns\n",
    "playersWorlds = pd.DataFrame(np.array(players).reshape(90,20), columns = ['Team','Player','Games','Wins','Losses','Winrate','Kills','Deaths','Assists','KDA','CS','CSPM','Gold','GPM','Kill Participation','Kill Share','Gold Share','Champions Played','19','20'])\n",
    "\n",
    "# Drop unnecessary columns\n",
    "playersWorlds = playersWorlds.drop(['19','20'],axis=1)\n",
    "\n",
    "# Get numeric data\n",
    "playersWorlds['Games'] = playersWorlds['Games'].str.extract('(\\d+)', expand=False)\n",
    "playersWorlds['Gold'] = playersWorlds['Gold'].str[:-1]\n",
    "playersWorlds['Kill Participation'] = playersWorlds['Kill Participation'].str[:-1]\n",
    "playersWorlds['Kill Share'] = playersWorlds['Kill Share'].str[:-1]\n",
    "playersWorlds['Gold Share'] = playersWorlds['Gold Share'].str[:-1]\n",
    "\n",
    "#playersWorlds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Regular season data for each region\n",
    "# We also took precautions and decided to save this to a csv file once we combined all of the data together from each region.\n",
    "\n",
    "ls = []\n",
    "reg = []\n",
    "\n",
    "# Parse with lxml\n",
    "ls.append(BeautifulSoup(r2.text, \"lxml\"))\n",
    "ls.append(BeautifulSoup(r3.text, \"lxml\"))\n",
    "ls.append(BeautifulSoup(r4.text, \"lxml\"))\n",
    "ls.append(BeautifulSoup(r5.text, \"lxml\"))\n",
    "ls.append(BeautifulSoup(r6.text, \"lxml\"))\n",
    "ls.append(BeautifulSoup(r7.text, \"lxml\"))\n",
    "\n",
    "j = 0\n",
    "for bs in ls:\n",
    "    \n",
    "    # split to get all the players individually\n",
    "    players = str(bs).split(\"std.png/45px\")[1:]\n",
    "\n",
    "    # split to get each column\n",
    "    for x in range (0,len(players)):\n",
    "        players[x] = players[x].split(\"</td>\")\n",
    "\n",
    "        # Get the player's name\n",
    "        players[x][1] = players[x][1].split(\"title=\\\"\")[1].split(\"\\\"\")[0]\n",
    "\n",
    "        # Get the team name\n",
    "        players[x][0] = players[x][0][1:].split(\"_std.png\")[0][:-4]\n",
    "\n",
    "        for y in range (2,17):\n",
    "            players[x][y] = players[x][y].split(\"center\\\">\")[1].split('\\n')[0]\n",
    "            \n",
    "        players[x][17] = players[x][17][-18:-16]\n",
    "\n",
    "    # Convert into data frame\n",
    "    reg.append(pd.DataFrame(np.array(players).reshape(len(players),len(players[0])), columns = ['Team','Player','Games','Wins','Losses','Winrate','Kills','Deaths','Assists','KDA','CS','CSPM','Gold','GPM','Kill Participation','Kill Share','Gold Share','Champions Played','19','20']))\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    reg[j] = reg[j].drop(['19','20'],axis=1)\n",
    "    \n",
    "    # Get just numeric data\n",
    "    reg[j]['Games'] = reg[j]['Games'].str.extract('(\\d+)', expand=False)\n",
    "    reg[j]['Champions Played'] = reg[j]['Champions Played'].str.extract('(\\d+)', expand=False)\n",
    "    reg[j]['Gold'] = reg[j]['Gold'].str[:-1]\n",
    "    reg[j]['Gold Share'] = reg[j]['Gold Share'].str[:-1]\n",
    "    reg[j]['Kill Participation'] = reg[j]['Kill Participation'].str[:-1]\n",
    "    reg[j]['Kill Share'] = reg[j]['Kill Share'].str[:-1]\n",
    "        \n",
    "    j = j+1\n",
    "\n",
    "# reg contains regular season data by region\n",
    "# reg[0] --> North America (NA)\n",
    "# reg[1] --> Europe (EU)\n",
    "# reg[2] --> China (LPL)\n",
    "# reg[3] --> Korea (LCK)\n",
    "# reg[4] --> Taiwan (LMS)\n",
    "# reg[5] --> Vietnam (VCS)\n",
    "\n",
    "# Convert data into numeric form\n",
    "for t in reg:\n",
    "    k=0\n",
    "    for col in t.columns:\n",
    "        if k>1 and k<18:\n",
    "            t[col] = pd.to_numeric(t[col])\n",
    "        k=k+1\n",
    "        \n",
    "# Sort the tables based on 'Games' and 'Player' to standardize the view\n",
    "reg[0] = reg[0].sort_values(['Games','Player'],ascending=[False,True])\n",
    "reg[1] = reg[1].sort_values(['Games','Player'],ascending=[False,True])\n",
    "reg[2] = reg[2].sort_values(['Games','Player'],ascending=[False,True])\n",
    "reg[3] = reg[3].sort_values(['Games','Player'],ascending=[False,True])\n",
    "reg[4] = reg[4].sort_values(['Games','Player'],ascending=[False,True])\n",
    "reg[5] = reg[5].sort_values(['Games','Player'],ascending=[False,True])\n",
    "\n",
    "# Get Position data for players from the regular season.\n",
    "# Position can be Top, JG, Mid, ADC, or Supp.\n",
    "\n",
    "# NOTE: This was hard-coded because the values won't change and it was more feasible than downloading 30 separate tables \n",
    "#       and just looking at a single column for each one.\n",
    "\n",
    "#pos = ['Top','ADC','Mid','JG','Top','Supp','Mid','Supp','ADC','Top','ADC','JG','JG','Mid','Top','Supp','Mid','Top','JG','JG','Mid','Mid','Supp','ADC','ADC','Top','Supp','ADC','Top','Top','Supp','ADC','Mid','Top','Supp','ADC','JG','Supp','Supp','JG','Mid','JG','Mid','JG','Top','Mid','ADC','Supp','ADC','ADC','JG','JG','Supp','Mid','JG','Mid','ADC','Top','Supp','JG','Supp','JG','ADC','Supp','Mid','JG','Top']\n",
    "pos = ['Supp', 'Mid', 'ADC', 'JG', 'Top', 'JG', 'Top', 'Top', 'Mid',\n",
    "       'Supp', 'Mid', 'JG', 'Top', 'ADC', 'ADC', 'ADC', 'Supp', 'Supp',\n",
    "       'JG', 'ADC', 'ADC', 'Mid', 'Mid', 'Top', 'Top', 'Top', 'Supp',\n",
    "       'Supp', 'Mid', 'Mid', 'Top', 'ADC', 'JG', 'Top', 'JG', 'ADC',\n",
    "       'Supp', 'Supp', 'JG', 'Mid', 'JG', 'Supp', 'JG', 'Mid', 'Top',\n",
    "       'Mid', 'Supp', 'ADC', 'ADC', 'ADC', 'JG', 'JG', 'Supp', 'Mid',\n",
    "       'Mid', 'JG', 'Top', 'ADC', 'Supp', 'Supp', 'Mid', 'JG', 'JG', 'ADC',\n",
    "       'Supp', 'JG', 'Top']\n",
    "reg[0]['Position'] = pos\n",
    "\n",
    "#pos1 = ['Mid','Mid','Supp','Supp','Top','Supp','JG','ADC','Top','Top','JG','ADC','Mid','ADC','Mid','JG','Supp','ADC','JG','Mid','Mid','Mid','ADC','Mid','ADC','JG','Mid','Top','Supp','Supp','Top','Supp','Supp','Top','Supp','Top','ADC','Top','JG','JG','Top','JG','ADC','Supp','ADC','Top','Mid','JG','JG','ADC','JG','JG','ADC','ADC','Mid','Supp']\n",
    "#pos1 = ['JG','ADC','Supp','Mid','Supp','Top','Supp','JG','ADC','Top','Top','Mid','Mid','ADC','JG','Mid','Mid','Mid','ADC','JG','Mid','Mid','ADC','Mid','ADC','JG','Top','Supp','Top','JG','Supp','JG','Top','JG','Top','Top','Supp','Supp','Supp','ADC','Top','Supp','ADC','ADC','Supp','Top','Mid','JG','ADC','JG','JG','ADC','JG','ADC','Mid','Supp']\n",
    "pos1 = ['JG', 'ADC', 'Top', 'ADC', 'Supp', 'JG', 'Mid', 'Mid', 'Mid', 'ADC',\n",
    "       'Supp', 'Top', 'Supp', 'Top', 'Top', 'Mid', 'Mid', 'JG', 'Mid',\n",
    "       'JG', 'Mid', 'ADC', 'ADC', 'Supp', 'Supp', 'ADC', 'JG', 'JG', 'JG',\n",
    "       'Mid', 'Supp', 'Top', 'Top', 'Supp', 'Top', 'Mid', 'Supp', 'Top',\n",
    "       'ADC', 'Supp', 'Top', 'JG', 'ADC', 'ADC', 'Supp', 'Top', 'Mid',\n",
    "       'JG', 'JG', 'JG', 'ADC', 'JG', 'ADC', 'ADC', 'Supp', 'Mid']\n",
    "reg[1]['Position'] = pos1\n",
    "\n",
    "#pos2 = ['Supp','ADC','JG','Supp','Top','Mid','Top','Mid','Supp','JG','JG','ADC','Mid','Top','Top','Mid','Mid','JG','ADC','Supp','Supp','ADC','ADC','Top','Supp','ADC','Supp','Supp','Top','Top','ADC','Mid','Mid','Mid','Top','Supp','ADC','Mid','JG','JG','Top','Top','JG','Mid','Supp','Supp','Supp','Top','ADC','Supp','JG','Mid','Top','JG','ADC','Mid','ADC','Mid','ADC','Supp','Mid','JG','JG','ADC','ADC','JG','Top','JG','ADC','JG','Mid','Top','JG','JG','Top','ADC','Mid','JG','JG','Supp','JG','Top','JG','ADC','ADC','Top','Mid','JG','JG','Mid','ADC','ADC','Top','Mid','Top','ADC','Supp','Supp','ADC','JG','Supp','Mid']\n",
    "pos2 = ['JG','ADC','Supp','Mid','Top','JG','Mid','Top','Top','Supp','ADC','Supp','Mid','Supp','Top','ADC','JG','JG','Mid','Supp','Mid','Supp','Top','Mid','ADC','Supp','ADC','Supp','Top','Mid','ADC','Top','ADC','JG','Supp','Top','Supp','Mid','ADC','Supp','Top','Mid','Top','JG','Supp','ADC','JG','Mid','Top','JG','ADC','JG','JG','Supp','Top','ADC','Mid','JG','Top','Mid','JG','ADC','ADC','Mid','ADC','Mid','JG','Supp','Top','JG','Top','Mid','JG','Top','Mid','JG','Top','ADC','ADC','JG','ADC','JG','Mid','JG','Supp','JG','ADC','Mid','Supp','ADC','Top','JG','JG','Top','ADC','Mid','ADC','ADC','JG','Supp','Mid','Supp']\n",
    "reg[2]['Position'] = pos2\n",
    "\n",
    "#pos3 = ['Supp','Mid','Top','ADC','Supp','Top','Supp','Mid','Supp','Top','ADC','Top','ADC','Mid','Supp','Supp','Top','Mid','JG','Mid','ADC','Supp','Top','JG','Supp','Mid','JG','Mid','Top','Top','Top','Mid','ADC','Top','ADC','Supp','ADC','JG','ADC','ADC','JG','ADC','JG','Mid','Supp','JG','JG','Mid','JG','JG','JG','JG','ADC','JG','JG','Mid','Supp','JG','ADC','JG','Supp','ADC','JG','Mid','ADC','Mid','Top','Top','ADC','Supp','Top']\n",
    "pos3 = ['Top', 'Mid', 'Supp', 'Supp', 'Mid', 'Top', 'Supp', 'ADC', 'JG',\n",
    "       'Top', 'ADC', 'Supp', 'Mid', 'ADC', 'Top', 'Mid', 'Top', 'Top',\n",
    "       'ADC', 'Supp', 'Supp', 'Supp', 'ADC', 'Mid', 'Top', 'Mid', 'ADC',\n",
    "       'Mid', 'Mid', 'Supp', 'Top', 'JG', 'JG', 'ADC', 'JG', 'Top', 'JG',\n",
    "       'ADC', 'Supp', 'ADC', 'Top', 'Supp', 'JG', 'JG', 'JG', 'ADC', 'Mid',\n",
    "       'JG', 'JG', 'Mid', 'Mid', 'JG', 'JG', 'ADC', 'JG', 'Supp', 'Mid',\n",
    "       'JG', 'JG', 'Supp', 'JG', 'ADC', 'ADC', 'JG', 'Mid', 'ADC', 'Supp',\n",
    "       'Top', 'ADC', 'Top', 'Top']\n",
    "reg[3]['Position'] = pos3\n",
    "\n",
    "#pos4 = ['Supp','Top','Mid','JG','Supp','Top','Top','JG','Supp','Supp','ADC','Supp','Mid','ADC','ADC','Mid','JG','Mid','Top','Supp','ADC','ADC','Mid','ADC','JG','Mid','ADC','Top','Supp','Supp','ADC','Top','JG','Mid','Top','JG','Mid','JG','ADC','Top','JG','Top','JG','ADC','JG','Mid','Top','JG','JG','Top','JG','Top','Supp','ADC','JG','Supp','Supp','Supp','JG','JG']\n",
    "pos4 = ['Supp', 'Top', 'JG', 'Mid', 'Top', 'Supp', 'ADC', 'Mid', 'ADC',\n",
    "       'Top', 'JG', 'Supp', 'Supp', 'JG', 'Mid', 'ADC', 'Supp', 'ADC',\n",
    "       'Supp', 'ADC', 'Mid', 'Top', 'ADC', 'Mid', 'JG', 'Mid', 'Top',\n",
    "       'ADC', 'Supp', 'Supp', 'Top', 'ADC', 'Top', 'JG', 'Mid', 'Mid',\n",
    "       'JG', 'JG', 'ADC', 'Top', 'JG', 'Top', 'ADC', 'JG', 'JG', 'Mid',\n",
    "       'Top', 'JG', 'JG', 'JG', 'Top', 'ADC', 'Top', 'Supp', 'JG', 'Supp',\n",
    "       'Supp', 'Supp', 'JG', 'JG']\n",
    "reg[4]['Position'] = pos4\n",
    "\n",
    "#pos5 = ['Top','ADC','Supp','Mid','ADC','Mid','Top','Top','Mid','Supp','Mid','JG','JG','JG','ADC','Mid','ADC','Top','Mid','Top','Supp','JG','ADC','Top','ADC','Supp','JG','ADC','Supp','JG','JG','Supp','Supp','Mid','Top','ADC','ADC','JG','Supp','Mid','Top','JG','Supp','Mid','Top','Top','Supp','Mid','JG','ADC','Supp','Supp','Supp','JG','Mid','Supp','JG','Top','JG','Mid']\n",
    "pos5 = ['ADC', 'Mid', 'Supp', 'Top', 'ADC', 'Top', 'JG', 'Mid', 'Supp',\n",
    "       'ADC', 'JG', 'Top', 'Mid', 'Mid', 'JG', 'Mid', 'ADC', 'Top', 'Supp',\n",
    "       'Mid', 'Top', 'JG', 'Top', 'ADC', 'Supp', 'ADC', 'JG', 'ADC',\n",
    "       'Supp', 'JG', 'Supp', 'JG', 'Supp', 'Top', 'Mid', 'ADC', 'ADC',\n",
    "       'JG', 'Supp', 'Mid', 'Top', 'JG', 'Supp', 'Mid', 'Top', 'Top',\n",
    "       'Supp', 'Mid', 'JG', 'ADC', 'Supp', 'Supp', 'Supp', 'Mid', 'JG',\n",
    "       'Supp', 'JG', 'Top', 'JG', 'Mid']\n",
    "reg[5]['Position'] = pos5\n",
    "\n",
    "# Combine regular season player data from each region into a master table\n",
    "masterReg = pd.concat(reg).sort_values(['Games','Player'],ascending=[False,True]).reset_index().drop('index',axis=1)\n",
    "#masterReg.to_csv('masterReg.csv')  # Save the data for use later on so we don't have to parse every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the table since we saved it already.\n",
    "masterReg = pd.read_csv(\"masterReg.csv\").drop(\"Unnamed: 0\",axis=1)\n",
    "\n",
    "# List of all column vars\n",
    "vars = ['KDA', 'GPM', 'Kill Share', 'Kill Participation', 'Kills', 'Deaths', 'Assists','Gold', 'Gold Share', 'CS', 'CSPM', 'Champions Played']\n",
    "\n",
    "# Create tables based on player position for our machine learning model.\n",
    "top = masterReg[masterReg['Position']=='Top']\n",
    "jg = masterReg[masterReg['Position']=='JG']\n",
    "mid = masterReg[masterReg['Position']=='Mid']\n",
    "adc = masterReg[masterReg['Position']=='ADC']\n",
    "supp = masterReg[masterReg['Position']=='Supp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Champion data from worlds\n",
    "\n",
    "# Parse with lxml\n",
    "bs = BeautifulSoup(r8.text, \"lxml\")\n",
    "\n",
    "# split to get all champions individually\n",
    "tmp = str(bs).split(\"Square.png/40px\")[1:]\n",
    "\n",
    "# split to get each column\n",
    "for x in range (0,len(tmp)):\n",
    "    \n",
    "    tmp[x] = tmp[x].split(\"</td>\")\n",
    "    \n",
    "    # Get the Champion's name\n",
    "    tmp[x][0] = tmp[x][0].split(\"title=\\\"\")[1].split(\"\\\"\")[0]\n",
    "    \n",
    "    # Get other column data\n",
    "    for y in range (1,19):\n",
    "        if y==5 or y==6:\n",
    "            tmp[x][y] = tmp[x][y].split(\"</b>\")[0]\n",
    "        if y != 7:\n",
    "            tmp[x][y] = tmp[x][y].split(\"center\\\">\")[1].split(\"\\n\")[0]\n",
    "    \n",
    "    t = tmp[x][7].split(\"_blank\\\">\") \n",
    "    tmp[x][7] = 0 if len(t)==1 else t[1][:2]\n",
    "\n",
    "# Convert into data frame with appropriate columns\n",
    "champs = pd.DataFrame(np.array(tmp).reshape(len(tmp),len(tmp[0])), columns = ['Champion','Bans','Games','Wins','Losses','Winrate','PB','By','Kills','Deaths','Assists','KDA','CS','CSPM','Gold','GPM','Kill Participation','Kill Share','Gold Share', '20'])\n",
    "\n",
    "# Drop unnecessary columns\n",
    "champs = champs.drop('20',axis=1)\n",
    "\n",
    "# Get just numeric data\n",
    "champs['By'] = champs['By'].str.extract('(\\d+)', expand=False)\n",
    "champs['Gold'] = champs['Gold'].str[:-1]\n",
    "champs['Kill Participation'] = champs['Kill Participation'].str[:-1]\n",
    "champs['Kill Share'] = champs['Kill Share'].str[:-1]\n",
    "champs['Gold Share'] = champs['Gold Share'].str[:-1]\n",
    "champs['Winrate'] = champs['Winrate'].str[3:]\n",
    "champs['PB'] = champs['PB'].str[3:]\n",
    "\n",
    "# Making data NaN for champs banned, but not played. Might want to drop these entries entirely though.\n",
    "pat = re.compile('-1')\n",
    "for col in champs.columns:\n",
    "    champs[col] = champs[col].replace(pat, np.nan)\n",
    "\n",
    "# Save the data as a csv so we don't have to parse it every time.\n",
    "champs.to_csv(\"champs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first bit of machine learning we want to do is determine what makes a player good. To do this, we will be using winrate\n",
    "# as our y value, and all of the different player statistics as our x variables. The results will tell us which of the\n",
    "# different variables are important and how important each one is individually. \n",
    "\n",
    "# First, we separated all of the data into their own positions, because what makes a mid laner good is probably different from\n",
    "# what makes a support good.\n",
    "\n",
    "# Next, we have to determine which variables we should be using to figure out their weights, or coefficients. To do this, we\n",
    "# created a powerset function that returns every possible combination of the variables we can have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code for this function was taken from:\n",
    "#     https://codereview.stackexchange.com/questions/178225/computing-the-powerset-of-a-list\n",
    "\n",
    "from itertools import chain\n",
    "from itertools import combinations\n",
    "\n",
    "# Powerset function of a given list\n",
    "def gen_powerset(l):\n",
    "    if not l:  # List is empty\n",
    "        yield []\n",
    "        return\n",
    "    for sub_powerset in gen_powerset(l[1:]): # Generate next list\n",
    "        yield sub_powerset\n",
    "        yield [l[0]] + sub_powerset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we removed outliers from the data that would significantly impact the results. This is due to us using winrate as our\n",
    "# measure of how good a player is. For example, if we have a substitute player that only played one game, and won, our algorithm\n",
    "# thinks that he is the best player in the world. To remove outliers, we tested each dataset with at least 'x' games played\n",
    "# by players to see what the cutoff should be. We don't want to remove more than 10 games, because that would encrouch on the\n",
    "# regular season starters for some regions, so we looked at 0-10 for each region.\n",
    "\n",
    "# The code below is linear regression in machine learning for predicitive analysis.\n",
    "\n",
    "# Source on what linear regression is and why we use it\n",
    "#  https://towardsdatascience.com/linear-regression-using-python-ce21aa90ade6\n",
    "  \n",
    "# Example of basic linear regression\n",
    "#  https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html\n",
    "\n",
    "# Source on linear regression of multi-variables, which is the type we did\n",
    "#  https://datatofish.com/multiple-linear-regression-python/\n",
    "\n",
    "# Source to understand the purpose and basic use of test and training data\n",
    "#  https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.893988370271\n",
      "1: 0.893988370271\n",
      "2: 0.875577693052\n",
      "3: 0.847706284473\n",
      "4: 0.904623303699\n",
      "5: 0.815746226433\n",
      "6: 0.933270580443\n",
      "7: 0.933270580443\n",
      "8: 0.927521733627\n",
      "9: 0.911363927907\n"
     ]
    }
   ],
   "source": [
    "# This is an example of how we determined the cutoffs for each position. This was done on the adc table.\n",
    "\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Must have played at least 0-10 games.\n",
    "for u in range(0,10):\n",
    "    \n",
    "    # All of the variables we want to look at\n",
    "    vars = ['KDA', 'GPM', 'Kill Share', 'Kill Participation', 'Kills', 'Deaths', 'Assists','Gold', 'Gold Share', 'CS', 'CSPM']\n",
    "\n",
    "    # Must have played at least 'u' games\n",
    "    tmp = adc[adc['Games'] >= u]\n",
    "\n",
    "    best = -1    # Keeps track of the best variance\n",
    "    bestLs = []  # Holds the list of variables for the best variance\n",
    "    coef = []    # Contains the coefficients for the variables\n",
    "    \n",
    "    # Set winrate to be our ranking for the players\n",
    "    y = tmp['Winrate']\n",
    "\n",
    "    # Look at every possible combination of variables for the players\n",
    "    for ps in gen_powerset(vars):\n",
    "        \n",
    "        if ps: # Dont include empty list\n",
    "            \n",
    "            X = tmp[ps]\n",
    "            \n",
    "            # Split data into test and training sets with an 80/20 split, which is standard to minimize overfitting.\n",
    "            # 80% of the data is used for training and the remaining 20% is used for testing.\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "            \n",
    "            # Fit the model to the training data\n",
    "            regr = linear_model.LinearRegression()\n",
    "            regr.fit(X_train, y_train)\n",
    "\n",
    "            #numpy array that contains all the predicted values for the input values in the X series.\n",
    "            y_pred = regr.predict(X_test)\n",
    "\n",
    "            # Get the variance score between the test data and our prediction. 1 would be a perfect score.\n",
    "            residuals = r2_score(y_test, y_pred)\n",
    "\n",
    "            # Keep track of the best score and which variables we used.\n",
    "            if residuals > best:\n",
    "                best = residuals\n",
    "                bestLs = ps\n",
    "                coef = regr.coef_\n",
    "                \n",
    "    print(str(u) + \": \" + str(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8674698795180723"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From this output, we see that if we look at just players that have played at least 6 games our variance goes all the way\n",
    "# up to a 93% accuracy. If we used every player, so at least 0 games played, we would have an 89% accuracy. In the end, this\n",
    "# should help our model be more consistent by removing outliers in the data. We're allowed to do this because it makes sense \n",
    "# heuristically, and we still have a sizeable portion of the regular data. This removes the problem of having a person that\n",
    "# went 1/1 in their games and our algorithm tries to use them as the best player.\n",
    "\n",
    "# By having 10 be our max we want to cut out, it ensures that we keep starters for each region, as well as players that split\n",
    "# time like the junglers for Cloud9, Svenskeren and Blaber. The only players we remove are substitutes.\n",
    "\n",
    "# This shows us that we are still using 86% of the main data, so we aren't cutting out a significant portion.\n",
    "len(adc[adc['Games']>=6])/len(adc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We repeated this process for each position and came up with the following numbers for minimum games played:\n",
    "#   top -  7\n",
    "#   jg -   2\n",
    "#   mid -  4\n",
    "#   adc -  6\n",
    "#   supp - 7\n",
    "\n",
    "# We adjust the position tables accordingly.\n",
    "top = top[top['Games']>=7]\n",
    "jg = jg[jg['Games']>=2]\n",
    "mid = mid[mid['Games']>=4]\n",
    "adc = adc[adc['Games']>=6]\n",
    "supp = supp[supp['Games']>=7]\n",
    "\n",
    "# The next step is to look at each position and figure out which variables we want to use now that we removed our outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOP MODEL\n",
    "\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Look at the top 20 results\n",
    "numResults = 20\n",
    "\n",
    "# Must have played at least 7 games\n",
    "tmp = top[top['Games'] >= 7]\n",
    "\n",
    "#These are the possible column variables to be tested in combinations\n",
    "vars = ['KDA', 'GPM', 'Kill Share', 'Kill Participation', 'Kills', 'Deaths', 'Assists','Gold', 'Gold Share', 'CS', 'CSPM']\n",
    "\n",
    "best = [-1]*numResults   # Array of top 20 variance scores\n",
    "bestLs = [-1]*numResults # Array of corresponding variables to each of the variance scores\n",
    "coef = [[-1]]*numResults # Array of weights associated with each of the variables producing the variance scores\n",
    "\n",
    "y = tmp['Winrate']\n",
    "\n",
    "for ps in gen_powerset(vars):\n",
    "    if ps:\n",
    "        X = tmp[ps]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "        regr = linear_model.LinearRegression()\n",
    "        regr.fit(X_train, y_train)\n",
    "        y_pred = regr.predict(X_test)\n",
    "        residuals = r2_score(y_test, y_pred)\n",
    "\n",
    "        # Compares and tracks the best variances\n",
    "        for x in range(0,len(best)):\n",
    "\n",
    "            if residuals > best[x]:\n",
    "                best[x] = residuals\n",
    "                bestLs[x] = ps\n",
    "                coef[x] = regr.coef_\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.940919486567\n",
      "0.940740800093\n",
      "0.935192176281\n",
      "0.934704981238\n",
      "0.933375784839\n",
      "0.931949972536\n",
      "0.931707708153\n",
      "0.931707060208\n",
      "0.931353160064\n",
      "0.930447728321\n",
      "0.930270861891\n",
      "0.92198441562\n",
      "0.918260985383\n",
      "0.912043773758\n",
      "0.911094817167\n",
      "0.910982731887\n",
      "0.910545559937\n",
      "0.910436807029\n",
      "0.909595880289\n",
      "0.909318036852\n"
     ]
    }
   ],
   "source": [
    "# Now lets look at the resulting variance scores\n",
    "for x in range(0,len(best)):\n",
    "    print(best[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Var: 0.940919486567\n",
      "Kill Participation: 0.418700301903\n",
      "Kills: -5.16785359036\n",
      "Gold: 33.7232065123\n",
      "Gold Share: -16.9243804411\n",
      "CS: -1.36556754429\n",
      "CSPM: 39.0278139619\n",
      "\n",
      "Var: 0.940740800093\n",
      "GPM: 0.303157161575\n",
      "Kill Participation: 0.457150749307\n",
      "Kills: -5.11081697126\n",
      "Gold: 24.1853257022\n",
      "Gold Share: -16.8753026582\n",
      "CS: -0.943283425008\n",
      "CSPM: 25.4547151316\n",
      "\n",
      "Var: 0.935192176281\n",
      "Kills: -6.13753753005\n",
      "Gold: 36.2673887188\n",
      "Gold Share: -15.6903854519\n",
      "CS: -1.4357446915\n",
      "CSPM: 37.9178569846\n",
      "\n",
      "Var: 0.934704981238\n",
      "GPM: -0.10315729985\n",
      "Kills: -6.12664451496\n",
      "Gold: 39.4334046626\n",
      "Gold Share: -15.7456460634\n",
      "CS: -1.57724517601\n",
      "CSPM: 42.5711500044\n",
      "\n",
      "Var: 0.933375784839\n",
      "KDA: 1.81620225498\n",
      "Kill Participation: 0.325639972329\n",
      "Kills: -5.52049460766\n",
      "Gold: 31.5349334345\n",
      "Gold Share: -14.6649990835\n",
      "CS: -1.28780694922\n",
      "CSPM: 35.6017579139\n",
      "\n",
      "Var: 0.931949972536\n",
      "KDA: 2.09811734882\n",
      "GPM: 0.593191309816\n",
      "Kill Participation: 0.386431392477\n",
      "Kills: -5.46362811076\n",
      "Gold: 12.5323771206\n",
      "Gold Share: -14.2182616141\n",
      "CS: -0.449448292041\n",
      "CSPM: 8.51130983888\n",
      "\n",
      "Var: 0.931707708153\n",
      "KDA: -1.4127120049\n",
      "GPM: 0.149140439495\n",
      "Kills: -4.67435876181\n",
      "Deaths: -6.22879046551\n",
      "Gold: 31.2835513521\n",
      "Gold Share: -12.6327701156\n",
      "CS: -1.23912259471\n",
      "CSPM: 26.1606931889\n",
      "\n",
      "Var: 0.931707060208\n",
      "Kill Participation: 0.382748647424\n",
      "Kills: -4.32957046657\n",
      "Deaths: -4.18292778501\n",
      "Gold: 32.2302150079\n",
      "Gold Share: -13.7818075469\n",
      "CS: -1.32816816654\n",
      "CSPM: 33.8941182987\n",
      "\n",
      "Var: 0.931353160064\n",
      "KDA: -3.84378101712\n",
      "Kill Participation: 0.538645262958\n",
      "Kills: -2.62597477795\n",
      "Deaths: -8.95959493279\n",
      "Gold: 35.1565287571\n",
      "Gold Share: -14.9748849797\n",
      "CS: -1.45003145377\n",
      "CSPM: 35.2825774567\n",
      "\n",
      "Var: 0.930447728321\n",
      "GPM: 0.666826489791\n",
      "Kill Participation: 0.46422226111\n",
      "Kills: -4.13177746471\n",
      "Deaths: -4.54386976931\n",
      "Gold: 11.1218003246\n",
      "Gold Share: -13.4026852617\n",
      "CS: -0.396082068987\n",
      "CSPM: 3.59565759673\n",
      "\n",
      "Var: 0.930270861891\n",
      "KDA: -3.51868213631\n",
      "GPM: 0.524208578718\n",
      "Kill Participation: 0.58950825268\n",
      "Kills: -2.61457139724\n",
      "Deaths: -8.83933981649\n",
      "Gold: 18.3151873491\n",
      "Gold Share: -14.5759397286\n",
      "CS: -0.706988883782\n",
      "CSPM: 11.3467850674\n",
      "\n",
      "Var: 0.92198441562\n",
      "KDA: -0.852678831993\n",
      "GPM: 0.411439054685\n",
      "Kill Share: 2.01489176107\n",
      "Kills: -14.6899837201\n",
      "Deaths: -4.46826615647\n",
      "Assists: 1.90198505951\n",
      "Gold: 26.2631478633\n",
      "Gold Share: -17.8399690469\n",
      "CS: -1.05910094278\n",
      "CSPM: 22.2750579887\n",
      "\n",
      "Var: 0.918260985383\n",
      "GPM: 0.441308741402\n",
      "Kill Share: 1.99282703012\n",
      "Kills: -14.960259793\n",
      "Deaths: -3.38619407979\n",
      "Assists: 1.52459759853\n",
      "Gold: 25.2126043019\n",
      "Gold Share: -17.8011824451\n",
      "CS: -1.01415881244\n",
      "CSPM: 20.9901128111\n",
      "\n",
      "Var: 0.912043773758\n",
      "Kill Share: 2.17658586033\n",
      "Kills: -16.6163434684\n",
      "Assists: 1.25897099502\n",
      "Gold: 41.3551010313\n",
      "Gold Share: -21.1382078993\n",
      "CS: -1.70982672042\n",
      "CSPM: 45.998191339\n",
      "\n",
      "Var: 0.911094817167\n",
      "Kill Share: 1.53613479248\n",
      "Kill Participation: 0.187647121323\n",
      "Kills: -12.5663910156\n",
      "Deaths: -3.19558815185\n",
      "Gold: 39.2815458153\n",
      "Gold Share: -18.2043026624\n",
      "CS: -1.64108177445\n",
      "CSPM: 41.0819261657\n",
      "\n",
      "Var: 0.910982731887\n",
      "GPM: 0.107733558965\n",
      "Kills: -5.55216640798\n",
      "Deaths: -4.23809059299\n",
      "Assists: -1.74069688514\n",
      "Gold: 34.8926998038\n",
      "Gold Share: -13.4099998467\n",
      "CS: -1.3938953303\n",
      "CSPM: 29.5460791835\n",
      "\n",
      "Var: 0.910545559937\n",
      "GPM: 0.305888707882\n",
      "Kill Share: 1.69483236231\n",
      "Kills: -13.7804177544\n",
      "Deaths: -3.35284017366\n",
      "Gold: 31.5336075379\n",
      "Gold Share: -17.8154895385\n",
      "CS: -1.27920364846\n",
      "CSPM: 27.2699635869\n",
      "\n",
      "Var: 0.910436807029\n",
      "KDA: 0.107658079247\n",
      "GPM: 0.111971185179\n",
      "Kills: -5.59944310027\n",
      "Deaths: -4.10027872735\n",
      "Assists: -1.7837806139\n",
      "Gold: 34.7465273467\n",
      "Gold Share: -13.4112413357\n",
      "CS: -1.38769014666\n",
      "CSPM: 29.3718829656\n",
      "\n",
      "Var: 0.909595880289\n",
      "KDA: 0.451612108484\n",
      "GPM: 0.339462824389\n",
      "Kill Share: 1.72221398459\n",
      "Kills: -14.0782472735\n",
      "Deaths: -2.78410521171\n",
      "Gold: 30.1484966013\n",
      "Gold Share: -17.7930709333\n",
      "CS: -1.22065238664\n",
      "CSPM: 25.7660995803\n",
      "\n",
      "Var: 0.909318036852\n",
      "Kills: -5.56823822995\n",
      "Deaths: -4.16728036182\n",
      "Assists: -1.80190299267\n",
      "Gold: 38.3570345431\n",
      "Gold Share: -13.5491447448\n",
      "CS: -1.54767984997\n",
      "CSPM: 34.5470981867\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We get scores from 94% to 90% in the top 20. Any of these would work for our model, but we will go through and pick\n",
    "# the one that makes the most sense heuristically with our League knowledge to ensure that the model won't incorrectly\n",
    "# predict data down the road. \n",
    "\n",
    "# This will show us the variance score, what variables it included and what the weights are for them.\n",
    "for x in range(0,len(coef)):\n",
    "    print(\"Var: \" + str(best[x]))\n",
    "    for y in range(0,len(coef[x])):\n",
    "        print(bestLs[x][y] + \": \" + str(coef[x][y]))\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Var: 0.910230242596\n",
      "GPM: 0.360191830749\n",
      "Deaths: -12.4258674915\n",
      "Gold: 16.8694294854\n",
      "CS: -0.663890630282\n",
      "\n",
      "Var: 0.908643011036\n",
      "Deaths: -12.3302827357\n",
      "Gold: 27.8538443911\n",
      "CS: -1.15038424901\n",
      "CSPM: 16.2471397181\n",
      "\n",
      "Var: 0.908544409426\n",
      "GPM: 0.866201561191\n",
      "Deaths: -13.902825841\n",
      "CSPM: -20.5040084763\n",
      "\n",
      "Var: 0.908438415827\n",
      "GPM: 0.848515826806\n",
      "Deaths: -12.5403884997\n",
      "Gold: 1.81980491572\n",
      "CSPM: -21.8503038605\n",
      "\n",
      "Var: 0.908436820699\n",
      "GPM: 0.905411280321\n",
      "Deaths: -12.6349084614\n",
      "CS: 0.0756606870073\n",
      "CSPM: -24.277379338\n",
      "\n",
      "Var: 0.908227018477\n",
      "GPM: -0.0722957467101\n",
      "Deaths: -12.3076414821\n",
      "Gold: 30.0518304474\n",
      "CS: -1.2473957677\n",
      "CSPM: 19.4740553881\n",
      "\n",
      "Var: 0.906279788697\n",
      "Kill Participation: -0.284084681602\n",
      "Deaths: -13.2507140027\n",
      "Gold: 28.3961522721\n",
      "CS: -1.15478832119\n",
      "CSPM: 15.9410548057\n",
      "\n",
      "Var: 0.905909163978\n",
      "KDA: 1.71587606658\n",
      "GPM: -0.0403304290385\n",
      "Deaths: -9.70588205849\n",
      "Gold: 27.0713492033\n",
      "CS: -1.11250045577\n",
      "CSPM: 17.2398191372\n",
      "\n",
      "Var: 0.90524934301\n",
      "GPM: -0.125563711538\n",
      "Kill Participation: -0.286565709857\n",
      "Deaths: -13.2194290342\n",
      "Gold: 32.2183645964\n",
      "CS: -1.32331700488\n",
      "CSPM: 21.5429092479\n",
      "\n",
      "Var: 0.902594434731\n",
      "KDA: 1.77052695788\n",
      "GPM: -0.0934431424009\n",
      "Kill Participation: -0.291207575747\n",
      "Deaths: -10.5495725831\n",
      "Gold: 29.1780486938\n",
      "CS: -1.18535505044\n",
      "CSPM: 19.2710240946\n",
      "\n",
      "Var: 0.901898303047\n",
      "GPM: 0.0713156133641\n",
      "Deaths: -13.0255264467\n",
      "Assists: 3.69342852617\n",
      "Gold: 19.8616597461\n",
      "CS: -0.845745453945\n",
      "CSPM: 12.7679155894\n",
      "\n",
      "Var: 0.901561235835\n",
      "GPM: 0.758421762388\n",
      "Kills: -9.64815235863\n",
      "Deaths: -12.3118439692\n",
      "Assists: 2.42859423399\n",
      "Gold: 13.7861376697\n",
      "CS: -0.556964360383\n",
      "CSPM: -9.05607062416\n",
      "\n",
      "Var: 0.895562088099\n",
      "GPM: 0.666659154169\n",
      "Kill Participation: -0.292361521784\n",
      "Kills: -8.99863241036\n",
      "Deaths: -13.3343031953\n",
      "Assists: 2.74107070176\n",
      "Gold: 15.7783029994\n",
      "CS: -0.629140850075\n",
      "CSPM: -5.88892546428\n",
      "\n",
      "Var: 0.891783301319\n",
      "Kill Participation: -0.31261080921\n",
      "Kills: -7.89326253673\n",
      "Deaths: -13.2853776988\n",
      "Assists: 2.81918126954\n",
      "Gold: 34.493277884\n",
      "CS: -1.45525634246\n",
      "CSPM: 22.8375484451\n",
      "\n",
      "Var: 0.88933712297\n",
      "KDA: -1.24406428504\n",
      "GPM: 0.712487129131\n",
      "Kills: -8.99912976665\n",
      "Deaths: -14.3634935853\n",
      "Assists: 3.11708574664\n",
      "Gold: 14.6909747491\n",
      "CS: -0.608574866516\n",
      "CSPM: -7.0637023129\n",
      "\n",
      "Var: 0.885268845855\n",
      "GPM: 0.350234850569\n",
      "Kill Share: -0.928983200708\n",
      "Kill Participation: 0.0312375767493\n",
      "Kills: -3.4163445027\n",
      "Deaths: -13.6289756635\n",
      "Gold: 23.5882409378\n",
      "CS: -0.980703536594\n",
      "CSPM: 7.42357283493\n",
      "\n",
      "Var: 0.884828611631\n",
      "GPM: 0.35278044446\n",
      "Kill Share: -0.906372423279\n",
      "Kills: -3.57554686235\n",
      "Deaths: -13.6820354466\n",
      "Gold: 23.7357085675\n",
      "CS: -0.984560103354\n",
      "CSPM: 7.33101451317\n",
      "\n",
      "Var: 0.882292406027\n",
      "GPM: 0.313585523266\n",
      "Kill Share: -1.00518055939\n",
      "Kills: -3.08728051518\n",
      "Deaths: -13.7818291491\n",
      "Assists: -0.476480441956\n",
      "Gold: 25.2322717563\n",
      "CS: -1.04652212916\n",
      "CSPM: 9.06753517859\n",
      "\n",
      "Var: 0.880441489038\n",
      "Kill Share: -0.974654780398\n",
      "Kill Participation: 0.0343773864292\n",
      "Kills: -2.50972372046\n",
      "Deaths: -13.6503369805\n",
      "Gold: 33.1192092783\n",
      "CS: -1.40285432332\n",
      "CSPM: 22.4189388329\n",
      "\n",
      "Var: 0.87697363763\n",
      "Kill Share: -1.08466650551\n",
      "Kills: -2.12137248087\n",
      "Deaths: -13.8475821879\n",
      "Assists: -0.682393826382\n",
      "Gold: 33.9701692593\n",
      "CS: -1.43144900123\n",
      "CSPM: 22.5203844255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TEST MODEL\n",
    "\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Look at the top 20 results\n",
    "numResults = 20\n",
    "\n",
    "#These are the possible column variables to be tested in combinations\n",
    "vars = ['KDA', 'GPM', 'Kill Share', 'Kill Participation', 'Kills', 'Deaths', 'Assists','Gold', 'CS', 'CSPM']\n",
    "\n",
    "best = [-1]*numResults   # Array of top 20 variance scores\n",
    "bestLs = [-1]*numResults # Array of corresponding variables to each of the variance scores\n",
    "coef = [[-1]]*numResults # Array of weights associated with each of the variables producing the variance scores\n",
    "\n",
    "y = mid['Winrate']\n",
    "\n",
    "for ps in gen_powerset(vars):\n",
    "    if ps:\n",
    "        X = mid[ps]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "        regr = linear_model.LinearRegression()\n",
    "        regr.fit(X_train, y_train)\n",
    "        y_pred = regr.predict(X_test)\n",
    "        residuals = r2_score(y_test, y_pred)\n",
    "\n",
    "        # Compares and tracks the best variances\n",
    "        for x in range(0,len(best)):\n",
    "\n",
    "            if residuals > best[x]:\n",
    "                best[x] = residuals\n",
    "                bestLs[x] = ps\n",
    "                coef[x] = regr.coef_\n",
    "                break\n",
    "                \n",
    "for x in range(0,len(coef)):\n",
    "    print(\"Var: \" + str(best[x]))\n",
    "    for y in range(0,len(coef[x])):\n",
    "        print(bestLs[x][y] + \": \" + str(coef[x][y]))\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the results we came up with for each position.\n",
    "\n",
    "#  Top\n",
    "# Var: 0.931949972536\n",
    "# KDA: 2.09811734882\n",
    "# GPM: 0.593191309816\n",
    "# Kill Participation: 0.386431392477\n",
    "# Kills: -5.46362811076\n",
    "# Gold: 12.5323771206\n",
    "# Gold Share: -14.2182616141\n",
    "# CS: -0.449448292041\n",
    "# CSPM: 8.51130983888\n",
    "\n",
    "# For a top laner, it looks like you shouldn't be focusing on kills to let your team get them instead, but KDA is also positive\n",
    "# so that encourages you to have more assists. Gold is important, which makes sense because gold is used to buy items, which \n",
    "# makes you stronger. However, we see that Gold Share is fairly negative, meaning you should be getting gold, but not at the \n",
    "# expense of your team's gold.\n",
    "\n",
    "#  Jungle\n",
    "# Var: 0.934277194926\n",
    "# KDA: 0.181164206403\n",
    "# GPM: 0.735342254784\n",
    "# Kills: -2.68009575084\n",
    "# Deaths: -7.25541495648\n",
    "# Assists: 1.85733953438\n",
    "# Gold: 7.16660335062\n",
    "# Gold Share: -14.1978168455\n",
    "# CS: -0.385377553174\n",
    "# CSPM: 10.493478078\n",
    "\n",
    "# Jungle follows roughly the same logic as top: you want assists, not kills, and you don't want to take a large portion of the\n",
    "# team's gold.\n",
    "\n",
    "#  Mid\n",
    "# Var: 0.901898303047\n",
    "# GPM: 0.0713156133641\n",
    "# Deaths: -13.0255264467\n",
    "# Assists: 3.69342852617\n",
    "# Gold: 19.8616597461\n",
    "# CS: -0.845745453945\n",
    "# CSPM: 12.7679155894\n",
    "\n",
    "# For some reason the algorithm wanted to have use Gold Share and have it be negative, which doesn't really make sense for a mid\n",
    "# laner, because you normally want them to have a high percentage of the team's gold. I think the reason this happened is because\n",
    "# of the data itself. Gold Share, no matter of the position, is always going to be around 20% because it's split between 5 people.\n",
    "# Because we didn't think this would be a good predictor, we excluded it from our results and looked for a different model. This\n",
    "# is what we came up with, which still works pretty well. It has a focus on Gold, CSPM, and assists, while also punishing deaths.\n",
    "\n",
    "#  ADC\n",
    "# Var: 0.933270580443\n",
    "# KDA: 0.879083138604\n",
    "# GPM: 1.13044121708\n",
    "# Kill Share: 1.03542306739\n",
    "# Kill Participation: -0.335817323575\n",
    "# Kills: -12.9697993181\n",
    "# Assists: 4.65262777296\n",
    "# CS: 0.128173966315\n",
    "# CSPM: -11.2995505544\n",
    "# Gold Share: -12.5435852695\n",
    "\n",
    "# We ran into the same issue with Gold Share when doing the adc data, but without Gold Share included the variance scores dropped\n",
    "# too low to be used. To rectify this, we just used the top result and decided not to influence the results in any way. The model\n",
    "# seems to think that kills, gold share, kill participation, and cspm are all negative, which is counter-intuitive for any\n",
    "# league of legends adc. Normally your job is to get kills, be involved, and get as much gold as you can so that you can carry\n",
    "# your team by dealing the most damage. Since this doesn't line up with our intuition, we'll see how the results are at the end\n",
    "# and talk more about this.\n",
    "\n",
    "#  Supp\n",
    "# Var: 0.915741666545\n",
    "# KDA: 0.0316139479741\n",
    "# GPM: 1.338934096\n",
    "# Kill Share: -0.145858503846\n",
    "# Kills: -3.99163808505\n",
    "# Deaths: -6.05433184202\n",
    "# Gold Share: -23.0728233467\n",
    "\n",
    "# For a support, kills should be negative because you don't want to be taking kills/gold away from your team. Again this follows\n",
    "# roughly the same pattern as top and jungle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we will use the weights we got from our machine learning and use them to calculate a player's winrate. We then take\n",
    "# the calculated value and add it to the corresponding position table.\n",
    "\n",
    "top['CalculatedWinrate'] = 2.09811734882*top['KDA'] + 0.593191309816*top['GPM'] + 0.386431392477*top['Kill Participation'] + -5.46362811076*top['Kills'] + 12.5323771206*top['Gold'] + -14.2182616141*top['Gold Share'] + -0.449448292041*top['CS'] + 8.51130983888*top['CSPM']\n",
    "jg['CalculatedWinrate'] = 0.181164206403*jg['KDA'] + 0.735342254784*jg['GPM'] + -2.68009575084*jg['Kills'] + -7.25541495648*jg['Deaths'] + 1.85733953438*jg['Assists'] + 7.16660335062*jg['Gold'] + -14.1978168455*jg['Gold Share'] + -0.385377553174*jg['CS'] + 10.493478078*jg['CSPM']\n",
    "mid['CalculatedWinrate'] = mid['GPM']*0.0713156133641 + mid['Deaths']*-13.0255264467 + mid['Gold']*19.8616597461 + mid['CS']*-0.845745453945 + mid['CSPM']*12.7679155894 + mid['Assists']*3.69342852617\n",
    "adc['CalculatedWinrate'] = 1.13044121708*adc['GPM'] + 1.03542306739*adc['Kill Share'] + -0.335817323575*adc['Kill Participation'] + -12.9697993181*adc['Kills'] + 4.65262777296*adc['Assists'] + 0.128173966315*adc['CS'] + -11.2995505544*adc['CSPM'] + -12.5435852695*adc['Gold Share']\n",
    "supp['CalculatedWinrate'] = 1.338934096*supp['GPM'] + -0.145858503846*supp['Kill Share'] + -3.99163808505*supp['Kills'] + -6.05433184202*supp['Deaths'] + -23.0728233467*supp['Gold Share']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now we can use machine learning to predict games. First we need to calculate the difference in the calculated winrate\n",
    "# for each position and save them as variables. These will be the independent variables for our ML and the dependent variable\n",
    "# will be which team won, a value either 0 or 100.\n",
    "\n",
    "teams = {}                # Dictionary ('Team' -> [topDiff, jgDiff,...])\n",
    "nadd = [[],[],[],[],[]]   # Contains new columns to be added to masterMatch\n",
    "\n",
    "# Go through each game we have data saved for.\n",
    "for index,row in masterMatch.iterrows():\n",
    "    \n",
    "    x1 = [] # Team 0 data\n",
    "    x2 = [] # Team 1 data\n",
    "    \n",
    "    # If we haven't seen this team yet, add it to the dictionary\n",
    "    if not row['Team 0'] in teams:\n",
    "        tmp = []\n",
    "        tmp.append(top[top['Team']==row['Team 0']])\n",
    "        tmp.append(jg[jg['Team']==row['Team 0']])\n",
    "        tmp.append(mid[mid['Team']==row['Team 0']])\n",
    "        tmp.append(adc[adc['Team']==row['Team 0']])\n",
    "        tmp.append(supp[supp['Team']==row['Team 0']])\n",
    "        \n",
    "        for x in tmp:\n",
    "            if len(x) == 1: # If there's only 1 player at that position, add them in\n",
    "                x1.append(x['CalculatedWinrate'])\n",
    "            else:\n",
    "                x1.append(x['CalculatedWinrate'].mean())  # If there are multiple players, we take the average\n",
    "                \n",
    "        # Save the team data in the dictionary for use later on\n",
    "        teams[row['Team 0']] = x1\n",
    "        \n",
    "    else:\n",
    "        x1 = teams[row['Team 0']]\n",
    "    \n",
    "    # Repeat the process for the next team\n",
    "    if not row['Team 1'] in teams:\n",
    "        tmp = []\n",
    "        tmp.append(top[top['Team']==row['Team 1']])\n",
    "        tmp.append(jg[jg['Team']==row['Team 1']])\n",
    "        tmp.append(mid[mid['Team']==row['Team 1']])\n",
    "        tmp.append(adc[adc['Team']==row['Team 1']])\n",
    "        tmp.append(supp[supp['Team']==row['Team 1']])\n",
    "        \n",
    "        for x in tmp:\n",
    "            if len(x) == 1:\n",
    "                x2.append(x['CalculatedWinrate'])\n",
    "            else:\n",
    "                x2.append(x['CalculatedWinrate'].mean())\n",
    "                \n",
    "        teams[row['Team 1']] = x2\n",
    "    \n",
    "    else:\n",
    "        x2 = teams[row['Team 1']]\n",
    "       \n",
    "    # Calculate the difference for each lane\n",
    "    for x in range(0,5):\n",
    "        nadd[x].append(float(x1[x]) - float(x2[x]))\n",
    "    \n",
    "# Update masterMatch with the new data\n",
    "masterMatch['TopDiff'] = nadd[0]\n",
    "masterMatch['JGDiff'] = nadd[1]\n",
    "masterMatch['MidDiff'] = nadd[2]\n",
    "masterMatch['ADCDiff'] = nadd[3]\n",
    "masterMatch['SuppDiff'] = nadd[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Var: 0.300341143566\n",
      "[-0.12769662 -0.09652615  0.00205015  0.28178966  1.12903653]\n"
     ]
    }
   ],
   "source": [
    "# Now we can run ML on the masterMatch table using our calculated differences as the X, and the winner result as the y.\n",
    "\n",
    "tester = masterMatch\n",
    "\n",
    "# Calculated Differences\n",
    "vars = ['TopDiff','JGDiff','MidDiff','ADCDiff','SuppDiff']\n",
    "\n",
    "y = tester['Winner']  # Winner data\n",
    "\n",
    "X = tester[vars]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred = regr.predict(X_test)\n",
    "residuals = r2_score(y_test, y_pred)\n",
    "                \n",
    "print(\"Var: \" + str(residuals))\n",
    "print(regr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From our results, we can see that our variance score is 30%. This isn't ideal, especially considering we were expecting at\n",
    "# least a value over 50%, which would be a blind guess. The model seems to think that top and jungle are negatively weighted,\n",
    "# meaning that teams with a worse top and jungle will win a game. This is counter-intuitive to us because normally the team\n",
    "# with better players wins more often. It is also worth noting that support is the largest value here by a decent margin,\n",
    "# implying that teams with a better support win more often. Who knows? Maybe support is the most important position. The data\n",
    "# seems to think so. Now we will simulate matches in Worlds to see how well the model does, despite it going against our \n",
    "# intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Simulate matches! Just enter 2 teams and look at the result! It's that easy!\n",
    "# Negative means the team on the right will win. Positive means the team on the left will win\n",
    "\n",
    "def matchup(team1,team2):\n",
    "    l = teams[team1]\n",
    "    l2 = teams[team2]\n",
    "\n",
    "    # Get the data to be the right type\n",
    "    for x in range(0,5):\n",
    "        if isinstance(l[x],pd.Series):\n",
    "            l[x] = l[x].values[0]\n",
    "    for x in range(0,5):\n",
    "        if isinstance(l2[x],pd.Series):\n",
    "            l2[x] = l2[x].values[0]\n",
    "\n",
    "    t = l[0] - l2[0]   # Calculate the differences\n",
    "    j = l[1] - l2[1]\n",
    "    m = l[2] - l2[2]\n",
    "    a = l[3] - l2[3]\n",
    "    s = l[4] - l2[4]\n",
    "\n",
    "    # Calculate the results\n",
    "    res = t*-0.12769662 + j*-0.09652615 + m*0.00205015 + a*0.28178966  + s*1.12903653\n",
    "\n",
    "    if res>0:\n",
    "        print(\"The winner is \" + team1 + \" by a differential of \" + str(res))\n",
    "        return team1\n",
    "    else:\n",
    "        print(\"The winner is \" + team2 + \" by a differential of \" + str(res))\n",
    "        return team2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "regRank = {}\n",
    "regRank[0] = 2\n",
    "regRank[1] = 4\n",
    "regRank[2] = 6\n",
    "regRank[3] = 5\n",
    "regRank[4] = 3\n",
    "regRank[5] = 1\n",
    "\n",
    "# Simulate matches! Just enter 2 teams and look at the result! It's that easy!\n",
    "# Negative means the team on the right will win. Positive means the team on the left will win\n",
    "\n",
    "def matchup2(team1,team2):\n",
    "    l = teams[team1]\n",
    "    l2 = teams[team2]\n",
    "\n",
    "    # Get the data to be the right type\n",
    "    for x in range(0,5):\n",
    "        if isinstance(l[x],pd.Series):\n",
    "            l[x] = l[x].values[0]\n",
    "    for x in range(0,5):\n",
    "        if isinstance(l2[x],pd.Series):\n",
    "            l2[x] = l2[x].values[0]\n",
    "\n",
    "    t = l[0] - l2[0]   # Calculate the differences\n",
    "    j = l[1] - l2[1]\n",
    "    m = l[2] - l2[2]\n",
    "    a = l[3] - l2[3]\n",
    "    s = l[4] - l2[4]\n",
    "    r = regRank[region(team1)] - regRank[region(team2)]\n",
    "\n",
    "    # Calculate the results\n",
    "    res = t*-0.12769662 + j*-0.09652615 + m*0.00205015 + a*0.28178966  + s*1.12903653 + r\n",
    "\n",
    "    if res>0:\n",
    "        print(\"The winner is \" + team1 + \" by a differential of \" + str(res))\n",
    "        return team1\n",
    "    else:\n",
    "        print(\"The winner is \" + team2 + \" by a differential of \" + str(res))\n",
    "        return team2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will simulate the group stage, by doing a round-robin of the teams in each group and ranking them by wins.\n",
    "group = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The winner is G2_Esports by a differential of -7.59257852655\n",
      "The winner is Yoe_Flash_Wolves by a differential of -33.5937021322\n",
      "The winner is Phong_V%C5%A9_Buffalo by a differential of -34.0954259184\n",
      "The winner is Yoe_Flash_Wolves by a differential of -26.0011236057\n",
      "The winner is Phong_V%C5%A9_Buffalo by a differential of -26.5028473918\n",
      "The winner is Phong_V%C5%A9_Buffalo by a differential of -0.501723786161\n",
      "The winner is Cloud9 by a differential of -11.4449287964\n",
      "The winner is Royal_Never_Give_Up by a differential of -6.211095539\n",
      "The winner is Team_Vitality by a differential of 1.48098919366\n",
      "The winner is Cloud9 by a differential of 5.23383325735\n",
      "The winner is Cloud9 by a differential of 12.92591799\n",
      "The winner is Royal_Never_Give_Up by a differential of 7.69208473266\n",
      "The winner is KTRolster by a differential of 1.07210588362\n",
      "The winner is MAD_Team by a differential of -0.196461381495\n",
      "The winner is Team_Liquid by a differential of -6.6466312053\n",
      "The winner is MAD_Team by a differential of -1.26856726511\n",
      "The winner is Team_Liquid by a differential of -7.71873708891\n",
      "The winner is Team_Liquid by a differential of -6.4501698238\n",
      "The winner is Invictus_Gaming by a differential of 24.2330096612\n",
      "The winner is Invictus_Gaming by a differential of 29.7793616007\n",
      "The winner is Invictus_Gaming by a differential of 52.5276577494\n",
      "The winner is Fnatic by a differential of 5.54635193955\n",
      "The winner is Fnatic by a differential of 28.2946480882\n",
      "The winner is 100_Thieves by a differential of 22.7482961486\n"
     ]
    }
   ],
   "source": [
    "# Now we will simulate the group stage, by doing a round-robin of the teams in each group and ranking them by wins.\n",
    "# We input all of the teams in each group as a list and go through each group, storing the resulting dataframe in 'group'\n",
    "from itertools import combinations\n",
    "group = []\n",
    "rank = {}\n",
    "groupTeams = []\n",
    "groupTeams.append([\"Freecs\", \"G2_Esports\", \"Yoe_Flash_Wolves\", \"Phong_V%C5%A9_Buffalo\"])\n",
    "groupTeams.append([\"Team_Vitality\", \"Cloud9\", \"Royal_Never_Give_Up\", \"Gen.G\"])\n",
    "groupTeams.append([\"KTRolster\", \"EDward_Gaming\", \"MAD_Team\", \"Team_Liquid\"])\n",
    "groupTeams.append([\"Invictus_Gaming\", \"Fnatic\", \"100_Thieves\", \"G-Rex\"])\n",
    "\n",
    "for l in groupTeams:\n",
    "    for x in l:\n",
    "        rank[x] = 0\n",
    "\n",
    "    l2 = list(combinations(l,2))\n",
    "\n",
    "    for x in range(0,len(l2)):\n",
    "        winner = matchup(l2[x][0],l2[x][1])\n",
    "        rank[winner] = rank[winner]+1\n",
    "\n",
    "    final = []\n",
    "    for x in l:\n",
    "        final.append([x,rank[x]])\n",
    "\n",
    "    group.append(pd.DataFrame(final,columns=['Team','Wins']).sort_values('Wins',ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Team  Wins\n",
      "3  Phong_V%C5%A9_Buffalo     3\n",
      "2       Yoe_Flash_Wolves     2\n",
      "1             G2_Esports     1\n",
      "0                 Freecs     0\n",
      "                  Team  Wins\n",
      "1               Cloud9     3\n",
      "2  Royal_Never_Give_Up     2\n",
      "0        Team_Vitality     1\n",
      "3                Gen.G     0\n",
      "            Team  Wins\n",
      "3    Team_Liquid     3\n",
      "2       MAD_Team     2\n",
      "0      KTRolster     1\n",
      "1  EDward_Gaming     0\n",
      "              Team  Wins\n",
      "0  Invictus_Gaming     3\n",
      "1           Fnatic     2\n",
      "2      100_Thieves     1\n",
      "3            G-Rex     0\n"
     ]
    }
   ],
   "source": [
    "# These are the results for the group stage with our model.\n",
    "# GROUP A: 4,3,2,1. It predicted the teams in reverse order, which isn't ideal.\n",
    "# GROUP B: 2,1,3,4. It got 2/4 correct, but just switched first and second place. That's really good though because the\n",
    "#                   top 2 teams from each group move on, so it predicted those teams correctly, it just messed up on the seeding.\n",
    "# GROUP C: 3,4,1,2. It was almost in reverse order, and didn't get any of the finalists correctly.\n",
    "# GROUP D: 2,1,3,4. It did the same as group B where it only switched the top 2 teams, which is pretty good.\n",
    "for g in group:\n",
    "    print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One reason the model might not be performing very well is that we aren't considering strength of schedule. For example, if one\n",
    "# team does really well during the regular season because they play against bad teams, the model thinks they're better than a \n",
    "# team that did decently well in a tough region. We can't add that in as a parameter because all of our data is teams playing\n",
    "# against each other in the same region, which would cancel out and become zero. Since we don't have any international data,\n",
    "# we can't do this with machine learning, so we will attempt to create our own model and incorporate it in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we need a way to tell what region a team is in.\n",
    "def region(teamName):\n",
    "    for x in range(0,6):\n",
    "        if teamName in matchReg[x]['Team 0'].unique():\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we need to actually rank the regions from best to worse.\n",
    "# Region ranking -> highest being the best\n",
    "regRank = {}\n",
    "regRank[0] = 2\n",
    "regRank[1] = 4\n",
    "regRank[2] = 6\n",
    "regRank[3] = 5\n",
    "regRank[4] = 3\n",
    "regRank[5] = 1\n",
    "\n",
    "# Our model from best to worst region: LPL, LCK, EU, LMS, NA, VCS.\n",
    "# This ranking is purely heuristic, and will only impact the data by a small amount. At most, it will change a result by 5\n",
    "# points. The results we've calculated range anywhere from 1 to 30, so it should have an impact, but not a large one. By doing\n",
    "# this, it will only impact matches that are really close and hopefully push them over the edge in our favor.\n",
    "\n",
    "# To incorporate this into the final ranking, the following line would be added to our group stage code:\n",
    "r = regRank[region(team1)] - regRank[region(team2)]\n",
    "\n",
    "# When we add in the regional difference, our results change for the group stage by a little.\n",
    "# In group A, it now ranks them 3,4,2,1 instead of 4,3,2,1. So it's a little better, but not by much.\n",
    "# In group C, it now ranks them 3,1,2,4 instead of 3,4,1,2. So again it's a little better.\n",
    "\n",
    "# If we had more time we would definitely look into grabbing some international data to train the model on regional difference\n",
    "# and add that in as a factor, because it would make the model slightly better.\n",
    "\n",
    "# Now that we finished the group stage, we will look at the elimination bracket given the starting teams in the bracket. The\n",
    "# following results are without the strength of schedule variable added in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimination Round Results:\n",
    "\n",
    "# Africa Freecs --\n",
    "#     16.9        >---Cloud9---\n",
    "# Cloud 9 --------             >\n",
    "#                      10.2    >-------Cloud9--------\n",
    "# Fnatic ---------             >                     >\n",
    "#     5.5         >---Fnatic---                      >\n",
    "# EDG ------------                                   >\n",
    "#                                         14         >---Invictus Gaming !!\n",
    "# KT Rolster -----                                   >\n",
    "#     28.7        >---Inv. G---                      >\n",
    "# Invictus Gaming-             >                     >\n",
    "#                      19.2    >---Invictus Gaming---\n",
    "# Royal Never G.--             >\n",
    "#      4          >----RNG-----\n",
    "# G2 Esports -----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The winner is Invictus_Gaming by a differential of -26.2330096612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Invictus_Gaming'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our model predicts all of the first round winners correctly, except for RNG vs. G2. This match was an upset, with G2 coming\n",
    "# out on top, and a lot of people had RNG winning the entire tournament. So it's reasonable that our code got it wrong, however,\n",
    "# despite that it only had RNG winning by a margin of 4, which is pretty close considering some of the other margins we have\n",
    "# between 10-30.\n",
    "\n",
    "# In the semifinals, we predicted Cloud9 to beat Fnatic, which was incorrect, and we predicted Invictus to move on, which was\n",
    "# correct.\n",
    "\n",
    "# In the final match, we predicted Invictus Gaming to win, which was correct. Just for fun, we also ran the actual final matchup,\n",
    "# which was Fnatic vs. Invictus Gaming, and the result was Invictus Gaming winning with a margin of 26. 26 is a pretty big\n",
    "# margin compared to some of the numbers we've been getting, and that makes sense because they won 3-0 in a best of 5 series.\n",
    "matchup(\"Fnatic\", \"Invictus_Gaming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The winner is Team_Liquid by a differential of 2.16124662892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Team_Liquid'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matchReg[5]\n",
    "matchup(\"Team_Liquid\", \"Fnatic\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is what our model thought would happen given the results of the group stage using the strength of schedule metric.\n",
    "\n",
    "# Flash Wolves ---\n",
    "#     18.9        >---Flash W---\n",
    "# Royal Never G.--             >\n",
    "#                      .3      >---Invictus Gaming---\n",
    "# Invictus Gaming-             >                     >\n",
    "#     29.7        >---Inv. G---                      >\n",
    "# KT Rolster -----                                   >\n",
    "#                                       1.8          >---Invictus Gaming\n",
    "# Team Liquid ----                                   >\n",
    "#     .16         >---Liquid---                      >\n",
    "# Fnatic ---------             >                     >\n",
    "#                      24.2    >-----PV Buffalo------\n",
    "# Cloud 9 --------             >\n",
    "#     16.2        >-PV Buffalo-\n",
    "# PV Buffalo -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we don't use the strength of schedule metric, then Flash Wolves would've won over Invictus Gaming, and \n",
    "# Phong Vu Buffalo would've beaten Invictus Gaming in the final. It is also worth noting that with the strength of schedule\n",
    "# metric, Fnatic almost beat Team Liquid; only losing by .16 instead of 2.16.\n",
    "\n",
    "# Overall, our model did pretty well considering the small amount of data we added in. We could have expanded this and included\n",
    "# data from every region, not just the ones that made it to worlds, and we could have added data from the spring split for\n",
    "# those regions. We also saw the importance of a strength of schedule metric that ended up being the deciding factor for some\n",
    "# close games. We did a very simple metric of just ranking regions 1-6 and taking the difference. This could've been done with\n",
    "# machine learning to figure out the weights for the difference to see how important it is, and we could've done some ML to\n",
    "# determine the rankings of each region, rather than doing it heuristically. With all of these factors in mind, it's pretty\n",
    "# impressive that the model worked as well as it did. We only looked at player data, and for each player we only used a portion\n",
    "# of their stats that the model told us to use. For some of the positions, ADC especially, these results were very counter\n",
    "# intuitive, like having kills and gold share be negatively weighed. Despite this, we trusted the model and went ahead with the\n",
    "# calculations and still predicted the winner of worlds correctly, even when we used our results from the group-stage that\n",
    "# weren't very good. \n",
    "\n",
    "# This model could easily be updated with new data as the tournament progressed too, hopefully making it more accurate.\n",
    "# For example, after the group stage you could add that player data to your existing data and be able to better predict the\n",
    "# eliminiation round. \n",
    "\n",
    "# Look up reference for this-> Another popular metric people use is having the data be weighed chronologically, where more recent\n",
    "# data is more important than older data. This could be another addition to make the model even better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
